---
title: "T1_BDML"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-02-01"
output: html_document
---

# Problem set 1:Modelo de salario individual por hora

## 1. Introducción

La Dirección de Impuestos y Aduanas Nacionales (DIAN) constituye la principal fuente de ingreso del Gobierno Central, según lo señala el Comité Autónomo de la Regla Fiscal (2024). Este ingreso es esencial para sostener los recursos fiscales de la Nación. Sin embargo, la economía colombiana enfrenta un significativo desafío: un déficit fiscal alimentado, en parte, por ingresos tributarios que, acumulados hasta noviembre de 2024, se situaron 10,8 billones de pesos por debajo de las proyecciones establecidas en el Marco Fiscal de Mediano Plazo (MFMP). Este marco define los límites de gasto del gobierno y es crucial para la estabilidad financiera del país.

González (2018) subraya la relevancia de la gestión de la DIAN en términos de control tributario y la utilización de diversas metodologías para combatir la evasión fiscal. Díaz y González (2024) añaden que una fiscalización efectiva depende de la implementación de instrumentos gerenciales, operativos, de medición y evaluación, capaces de identificar focos de evasión y contrabando.

Diversos estudios apuntan a que el problema de la evasión fiscal se debe a factores como el bajo nivel educativo de los contribuyentes, la falta de valores, la desconfianza en el gobierno y la baja eficiencia en la administración de los recursos públicos (Pinedo, del Aguila y Alvarado, 2022). Según estos autores, contribuyentes financieramente responsables suelen compartir características como una cultura tributaria sólida, un alto nivel educativo y un ingreso familiar estable.

Las medidas adoptadas por las instituciones para combatir la evasión fiscal son esenciales, especialmente en países en desarrollo donde esta práctica genera inequidad y desigualdad social. La evasión fiscal conduce a problemas como la baja recaudación de ingresos y el deterioro de las finanzas públicas, afectando la calidad de los servicios prestados por las entidades públicas. Un modelo de predicción de ingresos podría ser una herramienta útil para detectar casos de fraude y reducir esta brecha, además de identificar a personas y familias vulnerables que requieren asistencia.

Este fenómeno distorsiona el sistema tributario, reduce los ingresos destinados al financiamiento del gasto público y afecta la capacidad del gobierno para sostener programas esenciales en áreas clave como salud, educación e infraestructura. Además, la evasión fiscal genera inequidad, compromete la competitividad del país y puede impactar negativamente el desarrollo socioeconómico nacional. Al mismo tiempo la evasión fiscal trae consigo consecuencias negativas en la competitividad del país al desfavorecer a los empresarios que cumplen con sus obligaciones tributarias (Yikona, 2011).

Estudios como los de Espitia y Suárez (2017) y Rojas, Martínez, Álvarez y Farfán (2024) destacan cómo la evasión fiscal afecta la competitividad y contribuye al déficit fiscal, lo que puede llevar a una crisis financiera. La evasión fiscal es más frecuente en lugares con una alta informalidad laboral, donde los individuos son menos educados y con escasos recursos, lo que dificulta la recaudación efectiva de impuestos, reflejando una falta de confianza en el sistema y las instituciones. (Leopoldo Fergusson & Carlos Molina & Juan Felipe Riaño, 2017)

El presente trabajo se enfocará en la estimación de un modelo econométrico basado en datos de la Gran Encuesta Integrada de Hogares de 2018, realizada por el Departamento Administrativo Nacional de Estadística para Bogotá. Se analizarán las condiciones salariales de la población mayor de 18 años, utilizando diferentes métodos para predecir sus ingresos. La estructura del trabajo incluirá la descripción y limpieza de datos, el análisis de variables, la predicción de ingresos y las conclusiones y limitaciones del estudio.

## 2. Datos

### (a) Descripción de los datos

En la presente sección se realiza una descripción de los datos y el proceso de adquisición y limpieza obtenidos en la Gran Encuesta Integrada de Hogares (GEIH) para 2018, realizada por el Departamento Administrativo Nacional de Estadística para Bogotá del "Informe de Pobreza Monetaria y Desigualdad". Esta sección se enfoca en las personas empleadas mayores de dieciocho (18) años.

La GEIH proporciona información estadística del tamaño y estructura de la fuerza laboral, incluyendo datos sobre empleo, desempleo y población fuera de la fuerza de trabajo, los ingresos laborales y no laborales de los hogares, y la pobreza monetaria y extrema de la población residente en el país. Esta encuesta permite caracterizar a la población según sexo, edad, parentesco con el jefe del hogar, nivel educativo, afiliación al sistema de seguridad social en salud, grupos poblacionales y otras formas de trabajo, como producción de bienes y servicios para autoconsumo y trabajo en formación, entre otros.

La GEIH tiene una muestra anual aproximada de 315,000 hogares a nivel nacional, lo que le confiere una mayor cobertura y permite generar indicadores más confiables para los principales indicadores del mercado laboral.

### (b) Proceso de adquisición de los datos

#### Configuración inicial del ambiente de trabajo

Para llevar a cabo el análisis, utilizamos "pacman" para facilitar la carga e instalación de varios paquetes en R que permiten la recolección, manipulación, exploración y visualización de datos. Así mismo, utilizaremos "p_load( )" para instalar y cargar multiples paquetes en unsa sola línea de codigo como se muestra a continuación:

```{r}
if(!require(pacman)) install.packages("pacman") ; require(pacman)

p_load(rvest,     # Permite realizar web scraping en R
       dplyr,     # Permite manipulación y transformación de los datos
       skimr,     # Resumen estadístico
       visdat,    # Visualización de missing values
       corrplot,  # Correlation plots
       stargazer, # Tables/outputs to tex
       ggplot2,   # Graficación
       boot,      # Permite aplicar bootstrap
       tidyverse, # Análisis y tranformación de datos
       caret      # Predicción de modelos
       )
```

#### Proceso de extracción de datos

La base de datos se encuentra almacenada en una página web, por lo que se realizó un scrap del sitio web <https://ignaciomsarmiento.github.io/GEIH2018_sample/>. En primer lugar, se exploró la URL para identificar la información almacenada, evidenciando que se encontraba dividida en 10 data chunks. Se inspeccionó cada una de ellas y se realizó una iteración para consolidar la información de cada tabla y crear un dataframe llamado df_GEIH con 32.177 observaciones con 177 variables.

En el proceso de extraccción, se emplea el paquete `rvest` para analizar el contenido HTML y el paquete `dplyr` para combinar la lista de tablas en el dataframe, adicionalmente, se aplica una primera limpieza de los datos con el condicional `if` para eliminar la columna innecesaria de índice.

```{r}
# Lista tablas
todas_las_tablas <- list()

# Iterar en las 10 paginas
for (i in 1:10) {
  url_tabla <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", i, ".html")
  
  pagina_tabla <- read_html(url_tabla)
  
  # Extraer tabla
  tabla <- pagina_tabla %>% html_element("table") %>% html_table()
  
  # Agregar la tabla a la lista
  todas_las_tablas[[i]] <- tabla
}

# Unir todas las tablas en un solo dataframe
df_GEIH <- bind_rows(todas_las_tablas)

if ("...1" %in% colnames(df_GEIH)) {
  df_GEIH <- df_GEIH %>% select(-`...1`)
}
```

#### Proceso de limpieza de los datos

En primer lugar, se filtraron las personas ocupadas mayores de 18 años utilizando las variables "ocu" y "age". El término de personas ocupadas hace referencia a aquellos individuos que están trabajando en alguna actividad económica, ya sea de manera formal o informal, y que se encuentran dentro de la edad laboral. Para este análisis, se consideró que la edad legal para trabajar en Colombia es de 18 años, a partir de la cual no se aplican las restricciones que rigen para los menores de edad.

Lo anterior fue el resultado de la exploración de los datos, en la que se identificaron variables similares, como "ocu" y "dsi". Ambas son variables dicotómicas: "dsi" toma el valor de 1 si la persona está desempleada y 0 en caso contrario, mientras que "ocu" toma el valor de 1 si la persona está ocupada y 0 si no lo está. Dado que nuestro análisis se enfoca en las personas que están trabajando, se eligió la variable "ocu", ya que permite estudiar específicamente a las personas ocupadas. De este filtro, se da como resultado una base de datos con 16.542 observaciones con 177 variables.

```{r}
# Resumen de la Base de datos df_GEIH
skim(df_GEIH) %>% head()

df_GEIH %>%
  select(age, ocu) %>%  # Visualizar solo las columnas clave
  sample_n(10)  # Mostrar 10 filas aleatorias

# Verificar estructura de las variables clave
str(df_GEIH[, c("age", "ocu")])

# Filtrar personas mayores de 18 años que están empleadas
df_filtrado <- df_GEIH %>%
  filter(age >= 18, ocu == 1) 

head(df_filtrado)
```

#### Elección de variables

Se construye un nuevo dataframe a partir de la Gran Encuesta Integrada de Hogares (GEIH), seleccionando las variables relevantes para el presente análisis. El objetivo es modelar y explicar el salario por hora de una persona en función de diversas características individuales y laborales.

A continuación, se describen las variables elegidas y su pertinencia en la estimación del modelo, justificando su inclusión con base en la teoría económica y la literatura empírica sobre determinantes salariales.

-   **Y_total_m_ha (Ingreso total mensual):** Esta variable es la dependiente y capta el salario total mensual que recibe un trabajador, que es directamente el objeto de análisis en estudios de salarios.

-   **Age (Edad):** La edad influye en los salarios, ya que está vinculada a la experiencia laboral y las habilidades adquiridas a lo largo del tiempo. En general, la relación entre edad y salario es positiva hasta cierto punto, ya que la experiencia suele traducirse en mayores ingresos. Sin embargo, en etapas más avanzadas, esta relación puede estabilizarse o incluso disminuir. Según X, los jóvenes enfrentan tasas de desempleo más altas en el mercado laboral, mientras que las personas de mayor edad suelen experimentar períodos de desempleo más cortos, pero con una duración más prolongada. Orlando, A. (2000). DNP.

-   **Sex (Género):** Esta variable es una dummy que toma el valor de 1 si la persona es mujer y 0 si es hombre. Su relevancia radica en el análisis de las diferencias salariales entre géneros. En numerosos estudios económicos, se ha observado la existencia de una brecha salarial de género, donde, en promedio, las mujeres ganan menos que los hombres por realizar el mismo trabajo o tareas similares. La teoría de discriminación laboral de Joan Robinson (1933) sostiene que, aunque hombres y mujeres sean igualmente productivos, las mujeres recibirán un salario inferior debido a que la curva de oferta laboral femenina es menos elástica que la masculina. (Cuervo Alvarado, M., 2022).

-   **MaxEducLevel (Máximo nivel educativo):** El nivel educativo es una variable clave que afecta el salario. Los individuos con mayor nivel educativo suelen tener acceso a trabajos mejor remunerados debido a que se asocia con mayor capital humano, habilidades y capacidades técnicas como lo define la teoría planteada por Becker (1964).

-   **P6426 (Tiempo en la empresa):** Esta variable se refiere al número de años que una persona ha trabajado en la misma organización. Puede estar relacionada con el aumento salarial por antigüedad. Según Gary Becker y Robert E. Lucas Jr., el capital humano abarca las habilidades y cualidades que hacen a las personas más productivas, siendo así un motor clave para el desarrollo organizacional. Este capital se convierte en una ventaja fundamental para las empresas, permitiéndoles desempeñarse eficazmente en su entorno. (Cuervo Alvarado, M., 2022).

-   **P6870 (Tamaño de la empresa):** El tamaño de la empresa es una variable clave en la determinación salarial. Según Cuervo Alvarado (2022), las pequeñas empresas, que emplean de 1 a 10 personas, son determinantes en el tamaño y la producción de la industria. Sin embargo, en general, las empresas más grandes tienen una mayor capacidad económica, lo que les permite ofrecer salarios más altos y proporcionar mejores compensaciones a sus empleados.

-   **Depto (Departamento):** El departamento de un empleado puede influir en el salario. Diferentes departamentos tienen diferentes niveles de remuneración, dependiendo de la especialización, la demanda de las habilidades y el tipo de trabajo realizado.

-   **Formal (Formalidad del empleo):** Según Orlando (2000), en su informe del DNP, la formalidad del empleo se refiere a si el trabajador está registrado formalmente o si trabaja en la informalidad. Los trabajos formales suelen tener mejores salarios, beneficios y seguridad social, mientras que los trabajos informales presentan salarios más bajos y menor estabilidad.

-   **P6100 (Seguridad social):** La Organización Internacional del Trabajo hace referencia al régimen al que un trabajador está afiliado dentro del sistema de salud. El acceso a la seguridad social, especialmente a través de los diferentes regímenes (contributivo, especial y subsidiado), está estrechamente vinculado con la estabilidad económica y las oportunidades de ingresos.

```{r}
# Nuevo data frame
df_salario <- df_filtrado %>%
  select(y_total_m_ha, age, ocu, sex, maxEducLevel, p6426, p6870, depto, formal, p6100)

# cambio del nombre de algunas variables
df_salario <-  df_salario %>% 
  rename(salario_hora = y_total_m_ha,
         max_nivel_educ = maxEducLevel,
         tiempo_empresa = p6426,
         tamaño_empresa = p6870,
         segu_social = p6100
         )

# estadísticas de df_salario
skim(df_salario)
str(df_salario)
  
```

Así mismo, para poder trabjar con los datos de forma adecuda, es necesario realizar un análisis descirptivo de las variables seleccionadas como se muestra a continuación:

-   Tipos de datos:

    -   Numeric:

    -   Interger:

-   Estadísticas descriptivas por variables: (describir si tiene missing values, media, complete_rate, desviación estándar, cuartiles)

    -   salario_hora:

    -   age:

    -   ocu:

    -   sex:

    -   max_nivel_educ:

    -   tiempo_empresa:

    -   tamaño_empresa:

    -   depto:

    -   formal:

    -   segu_social:

#### Valores faltantes

Se procedió a identificar los datos faltantes. Para algunas variables, se utilizó el promedio de los valores disponibles, lo que resultó en una nueva base de datos denominada “df_salario” con 16,542 observaciones y 10 variables. Posteriormente, se calcularon los porcentajes de valores faltantes por cada variable y se graficó la distribución de estos porcentajes.

En cuanto a la imputación de los valores faltantes, se abordó de acuerdo con el tipo de variable. Para las variables categóricas, como educación y seguridad social, se ordenaron de manera descendente y se calculó el valor más común en cada categoría, que fue utilizado para reemplazar los datos faltantes.

Para la imputación de la variable continua, salario por hora, se analizó su distribución mediante un gráfico, observándose que presenta una cola hacia la derecha. Debido a esta distribución, se optó por imputar los valores faltantes con la mediana, ya que representa mejor el valor central de los datos. Finalmente, se verificó que no quedaran valores faltantes en la base de datos.

Con el resumen de estadísticas del nuevo data frame creado, se identifica la cantidad de valores faltantes (n_missing) en las variables salario_hora, segu_social y max_nivel_educ. A continuación, se procede a validar la información e imputar los valores faltantes de acuerdo a las caracterísitcas de las variables para poder estimar los modelos más adelante.

```{r}
# datos faltantes con skim
base_faltantes <- skim(df_salario) %>% select( skim_variable, n_missing)

# calcular el porcentaje de valores faltantes
obs <- nrow(df_salario) 

base_faltantes<- base_faltantes %>% mutate(p_missing = n_missing/obs)
head(base_faltantes)

# ordenar de forma descendente
base_faltantes <- base_faltantes %>% arrange(-n_missing)

# mantener solo las variables con valores faltantes
base_faltantes<- base_faltantes %>% filter(n_missing!= 0)
base_faltantes

# gráfica de los valores faltantes
ggplot(base_faltantes, aes(x = reorder(skim_variable, -n_missing), y = p_missing, fill = skim_variable)) +
  geom_bar(stat = "identity", color = "black", width = 0.5) +  
  scale_y_continuous(labels = scales::percent) +  
  scale_fill_manual(values = c("lightsalmon", "lightpink", "lightblue")) +  
  labs(title = "Porcentaje de valores faltantes por variables", 
       x = "Variables",
       y = "Porcentaje de valores faltantes") + 
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1))

# Imputación de valores faltantes con el Método 1: Media/Mediana

## Imputación de variables categóricas: max_nievl_educ y segu_social

### Calcular los valores mas comunes
educacion <- as.numeric(names(sort(table(df_salario$max_nivel_educ), decreasing = TRUE)[1]))

seg_soc <- as.numeric(names(sort(table(df_salario$segu_social), decreasing = TRUE)[1]))

### Imputación de los valores faltantes para ambas variables
df_salario <- df_salario  %>%
  mutate(max_nivel_educ = ifelse(is.na(max_nivel_educ) == TRUE, educacion , max_nivel_educ)) %>% 
  mutate(segu_social = ifelse(is.na(segu_social) == TRUE, seg_soc , segu_social))

## Imputación de variable continua: salario por hora

### Gráfica de la distribución del salario por hora
ggplot(df_salario, aes(salario_hora)) +
  geom_histogram(color = "#000000", fill = "#0099F8") +
  geom_vline(xintercept = median(df_salario$salario_hora, na.rm = TRUE), linetype = "dashed", color = "red") +
  geom_vline(xintercept = mean(df_salario$salario_hora, na.rm = TRUE), linetype = "dashed", color = "blue") +  
  ggtitle(" Ingreso Total por hora") +
  theme_classic() +
  theme(plot.title = element_text(size = 18))

#### Debido a que la distribución del ingreso total por hora tiene un cola a la derecha, se deicide utilizar la mediana para imputar los valores faltantes.

### Imputación de valores faltantes para variable continua
df_salario <- df_salario %>% 
  mutate(salario_hora = ifelse(is.na(salario_hora) == TRUE, median(df_salario$salario_hora, na.rm = TRUE) , salario_hora))

# Validación de la correcta imputación de valroes faltantes en el data frame de salario
sum(is.na(df_salario))
```

## 3. Perfil de edad-salario

Una gran cantidad de evidencia en economía laboral sugiere que el perfil de edad-salario del trabajador típico tiene una trayectoria predecible: “Los salarios tienden a ser bajos cuando el trabajador es joven; aumentan a medida que el trabajador envejece, alcanzando un máximo alrededor de los 50 años; y la tasa salarial tiende a permanecer estable o a disminuir ligeramente después de los 50 años”. En esta subsección vamos a estimar el perfil de edad-salario para los individuos de esta muestra:

En economia es usual formular modelos con variables que tengan una condicion cuadratica, este tipo de modelos lo que buscan es captar los efectos marginales decrecientes o crecientes en la funcion. En este sentido, el modelo de estimación planteado esta en funcion de una sola variables (age).

$$
log(w) = β_0 + β_1Age + β_2Age^2+ u    (2)
$$

Ademas, es importante recordar que el estimador $$β_1$$ no mide la variacion en $$Log (w)$$, porque, al realizar un analisis ceteris paribus sobre la variable $$Age^2$$, la variable $$age$$ será constante. Por lo tanto, la ecuación estimada, es:

$$
log(\hat{w})=\hat{β_0}+\hat{β_1}Age+\hat{β_2}Age^2
$$

De la estimación anterior, se tiene una aproximación luego de derivar la varible $$Log (w)$$ entre la variable $$Age$$, así

$$
\Delta log(\hat{w})/\Delta Age=\hat{β_1}+2\hat{β_2}Age
$$

Ahora, se puede mencionar que, la relación $$Log (w)$$ y $$\Delta Age$$ depende de la variable $$Age$$. Entonces, si se reemplaza el valor de 0 en la variable $$Age$$, se puede interpretar el coeficiente $$β_1$$ como el cambio marginal aproximado de pasar de 0 a 1. A continuación, estimaremos los coeficientes de la siguiente ecuación,

```{r}
#Estimacion de regresion log (salario)
modelo_age_wage <- lm(log(salario_hora) ~ age + I(age^2), data = df_salario) 

summary(modelo_age_wage)

```

# Interpretación de los resultados de la regresión log (salario)

El resultado de la estimación indica que el coeficiente $$Age$$ es positivo y $$Age^2$$ es negativo, esto predetermina que, valores pequeños en $$Age$$ tiene un efecto positivo en $$log(w)$$, por el contrario valores grandes en $$Age$$ genera una condicion de decrecimiento sobre el $$log(w)$$. De esta manera, tomaremos los multiplos de 18 años para realizar el analisis del cambio $$\Delta log(\hat{w})$$. Veamos, cuando la variable $$Age$$ es igual a 18 años, $$\Delta log(\hat{w})$$ es igual a 2,66% Ahora, cambiamos el valor a 36 años, $$$\Delta log(\hat{w})$$ es igual a 0,69% por último, $$Age$$ sera 54 años y por lo tanto $$\Delta log(\hat{w})$$ es igual a -1,29%.

```{r}
# Gráfico del perfil estimado de ingresos y edad

edades <- unique(df_salario$age)  

# Calcular los log salarios predichos por edad
log_salarios_predichos <- coef(modelo_age_wage)["(Intercept)"] +
                          coef(modelo_age_wage)["age"] * edades +
                          coef(modelo_age_wage)["I(age^2)"] * edades^2

# Data frame con salario log y reales
df_pred <- data.frame(
  edad = edades,
  log_salario = log_salarios_predichos,
  salario = exp(log_salarios_predichos)  
)

# Graficar el perfil estimado de ingresos y edad
ggplot(df_pred, aes(x = edad, y = salario)) +
  geom_line(color = "blue", size = 1) +
  geom_point(data = df_pred %>% filter(edad %% 10 == 0),  
             aes(x = edad, y = salario), color = "red", size = 2) +  # Puntos cada 10 años
  labs(title = "Perfil estimado de ingresos por hora según la edad",
       x = "Edad",
       y = "Salario promedio estimado") +
  theme_minimal()

```

Con el analisis anterior, podemos observar el comportamiento de la ecuación estimada es parabolico, es decir, en la "edad pico" se encuentra el punto de inflexión. Todas las edades menores a la "edad pico", la variable $$log(\hat{w})$$ será cerciente y para edades mayores a la "edad pico" la varible $$log(\hat{w})$$ seran decreciente. Asi las cosas, es necesario conocer como se calcula el punto de inflexión.

$$
\Delta log(\hat{w})/\Delta Age=0
$$

$$
\Delta log(\hat{w})/\Delta Age=\hat{β_1}+2\hat{β_2}Age
$$

$$
0=\hat{β_1}+2\hat{β_2}Age
$$

$$
Age_{pico}=-\hat{β_1}/2\hat{β_2}
$$

```{r}
# Obtener los coeficientes de la regresion log(w) = β0 + β1Age + β2Age2 + u

coefs <- modelo_age_wage$coef
coefs

```

```{r}
#Extraer los coeficientes de la regresión

b0 <- coefs [1] #Intercepto
b1 <- coefs [2] #age
b2 <- coefs [3] #age^2

```

```{r}
#Obtener la edad pico del problema segun los betas obtindos

peak_age <- -b1/(2*b2)
peak_age

```

El punto de inflexión de la ecuacion estimada donde esta localizada la edad pico corresponde a 42.25 años.

Significancia: Según los resultados obtenidos en la regresión todos los coeficientes obtenidos son estadisticamente significativos al 0.01 (99%).

Bondad de ajuste: El R² es 0.0194 y R² ajustado da el valor de 0.01932 , esto indica que el modelo explica el salario en un 1.93%. Estos valores bajores indican que el modelo captura una parte de la relación y existen otros factores que afectan el logaritmo de salario no incluidos en el modelo.

# Análisis de la “edad pico” con sus respectivos intervalos de confianza.

```{r}
# Función que obtiene los coefficientes de modelo

peak_age_fn <- function(data ,index) {
  
          coef_boot <- lm(log(salario_hora) ~ age + I(age^2), 
                          data = df_salario, 
                          subset = index)
          
          coef_boot_b0 <- coef_boot$coefficients [1]
          coef_boot_b1 <- coef_boot$coefficients [2]
          coef_boot_b2 <- coef_boot$coefficients [3]
          
          peak_age_boot <- -coef_boot_b1/(2*coef_boot_b2)
          
          return(peak_age_boot)
               }

# Validación de la edad pico desde la fila 1 hasta la fila 16542 
peak_age_fn(df_salario, 1:nrow(df_salario))

length(df_salario$age)

#Estimar la edad pico, sesgo y desviacion estandar por medio de Bootstrap

set.seed(123)

#LLamado de la función boot

peak_age_boot <- boot(df_salario, peak_age_fn,R=16542)
peak_age_boot

#Crear un data frame que almacene los resultado de peak_age_boot

peak_age_boot_df <- data.frame(peak_age = peak_age_boot$t)
summary(peak_age_boot_df)

#Calcular los cuantiles de confianza del peak_age_boot
quan_peak_age_boot <- quantile(peak_age_boot_df$peak_age, probs = c(0.025,0.975))
quan_peak_age_boot

#Graficar el histograma
hist(peak_age_boot_df$peak_age, las=1,
     main = "Distribución de muestra",
     xlim = c(41,44),
     xlab = "Edad",
     ylim = c(0,3000),
     ylab = "Frecuencia",
     col = "blue")

abline(v=quan_peak_age_boot, col = "green", lwd =2, lty=2)
legend("topright", legend = "Cuantiles", col = "green", lwd = 2, lty = 2)


```

## 4.La brecha salarial de género.

Los responsables de las políticas se han preocupado durante mucho tiempo por la brecha salarial de género.

$$
log(w) = β1 + β2Female + u
$$ donde Female es un indicador que toma uno si el individuo en la muestra se identifica como mujer.

```{r}
#Se crea la variable female en nuestra base

df_salario <- df_salario %>%
              mutate(female = ifelse(sex == 0, 1, 0))

#Estimación de regresion log (salario) con female
reg_female <- lm(formula = log(salario_hora) ~ female, data =df_salario)

stargazer(reg_female, type = "text")

```

\*Interpretación - Significancia global: El modelo es significativo al 0,01 (99%), es decir, la variable del modelo explica el salario por hora.

-   Bondad de ajuste: El R² es 0.002 y R² ajustado da el valor de 0.002 , esto indica que el modelo explica el salario en un 0.2%

-   El error estandar para este modelo es de0.787 y esto indica la dispersión entre las 16542 observaciones y la estimación.

-   Significancia parcial: La variable female es significativa al 0.01 (99%), el error estandar es de 0.012 y explica que si es mujer, en promedio el salario disminuye en 7.9%

## 4.1 Salario igual para trabajos iguales?

El eslogan "salario igual por trabajo igual" es una forma de interpretar que los empleados con características laborales similares, no debe existir ninguna brecha salarial de genero. En esta sección, se utilizará el modelo Frisch-Waugh-Lovell (FWL) para estimar la brecha salarial condicional, incorporando variables de control que reflejan las características semejantes de los trabajadores y los puestos de trabajo. El procedimiento se divide en tres pasos, que se describen a continuación:

Paso 1: Estimación de la regresión con todos los predictores completos, y cálculo de los residuos u. Paso 2: Se realiza una regresión auxiliar utilizando los residuos obtenidos en el paso anterior. Paso 3: El Teorema de Frisch-Waugh-Lovell establece que los residuos de la primera y segunda regresión son numéricamente equivalentes.

```{r}
# PASO 1
# Estimación de regresion log (salario) con female y otros controles
reg_female_controles <- lm(formula = log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                          data =df_salario)

# PASO 2
# Regresión auxiliar para obtener los residuos u
reg_female_residuos <- lm(formula = female  ~ max_nivel_educ + tiempo_empresa + age, 
                          data =df_salario)

residuos_female <- residuals(reg_female_residuos)

# PASO 3
#Correr la primera regresión con los residuos de female 
reg_residuos_female <- lm(log(salario_hora) ~ residuos_female, data = df_salario)


stargazer(reg_female_controles , reg_residuos_female, type = "text",
          column.labels = c("Modelo Condicional", "Modelo Incondicional"))
```

Análisis del modelo condicional e incondicional:

El coeficiente de la variable "female" en ambos modelos sugiere que, en promedio, las mujeres ganan un 10.7% menos que los hombres en salario por hora, incluso después de controlar por variables como el nivel educativo, la antigüedad en la empresa y la edad. Ambas variables son estadísticamente significativas, y se observa que el error estándar del coeficiente en el modelo condicional es 0.011, mientras que en el modelo incondicional es ligeramente más alto, 0.012.

El R² de ambos modelos es relativamente bajo, lo cual indica que estos modelos no tienen un buen ajuste con la muestra. Generalmente, se espera que el R² se acerque al 40%-80% para considerar los modelos más explicativo, pero en este caso ambos valores son menores (0.192) y (0.005), lo que sugiere que las variables elegidas no explican del todo las diferencias salariales.

El estadístico F en ambos modelos es significativo, lo que indica que al menos una de las variables es relevante para predecir el salario por hora. Sin embargo, el modelo condicional tiene un ajuste superior, ya que controla por variables clave que influyen en los salarios, lo que lo convierte en un modelo más robusto y confiable en comparación con el modelo incondicional.

De los resultados de las regresiones se puede observar que el teorema FWL se cumple porque los coeficientes de los betas son iguales.

```{r}
#Se comparan los coeficientes de female

beta_female_controles <- coef(reg_female_controles)["female"]
beta_femal_residuos <- coef(reg_residuos_female)["residuos_female"]

beta_female_controles 
beta_femal_residuos
```

Posteriomente, se estima el modelo FWL con Boostrap

```{r}
# Función para sacar residuales
fwl_boot <- function(data ,index) {
  
          coef(lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                          data = df_salario, 
                          subset = index))[2]
               }

# Validación
fwl_boot(df_salario, 1:nrow(df_salario))
  
# Semilla para hacerlo reproducible
set.seed(123)

# Estimaciones y errores estandar
errorestandar_boot <-  boot(df_salario, fwl_boot, R = 1000)
errorestandar_boot

```

Análisis de comparación de las estimaciones y los errores estándar

Al comparar las estimaciones de los coeficientes para female en los dos modelos (uno con controles y otro con los residuos de female), se observa que las estimaciones son prácticamente iguales cuando se utiliza el bootstrap. Sin embargo, los errores estándar son ligeramente diferentes entre los métodos con FWL y FWL con Boostrap. En el modelo estimado mediante el método FWL, el error estándar para female es de 0.011, mientras que en el modelo ajustado por los residuos de female, el error estándar aumenta ligeramente a 0.012. Aunque ambos valores son bastante similares, el modelo con los residuos refleja un pequeño aumento en la variabilidad de la estimación.

El valor del error estándar de la estimación de female mediante el método FWL con bootstrap es 0.01096617, lo que es consistente con los resultados obtenidos en el modelo con controles. Además, se observa que la variabilidad en la estimación de female es más baja en el modelo con bootstrap, en comparación con el modelo FWL ajustado por los residuos, lo que sugiere una mayor precisión en las estimaciones obtenidas mediante el bootstrap.

A pesar de estos pequeños cambios en los errores estándar, la brecha salarial de género sigue siendo evidente. El coeficiente negativo para female en ambos modelos indica que las mujeres ganan, en promedio, menos que los hombres, lo que confirma la persistencia de la brecha salarial.

Ahora, se graficará el perfil de edad- salario previsto y se calculará las edades pico implícitas con los respectivos intervalos de confianza por género

```{r}
ggplot(df_salario) + 
  geom_point(
    aes(x = age, y = log(salario_hora)),
    color = "darkred", size = 2
  ) + 
  labs(
    title = "Relación de edad y Salario por Horas",
    x = "Edad",
    y = "Ln Salario por horas"
  ) +
  theme_bw()

```

Discusión de edades pico a partir del gráfico (...)

Para concluir este análisis, retomamos lo que señala Sabogal (2012), quien destaca que en Colombia, las mujeres perciben salarios más bajos que los hombres, a pesar del aumento en su participación laboral, el mayor número de horas trabajadas y ciertas características observables, como el nivel educativo, durante las últimas tres décadas.

A partir de los resultados obtenidos en los modelos condicional e incondicional de la brecha salarial, se puede inferir que las variables contribuyen a un problema mixto que involucra tanto la selección como la discriminación salarial hacia las mujeres.

La selección no solo puede depender de características observables tales como la edad, la educación y la experiencia, sino también verse influida por factores históricos o estructurales de discriminación. Por ejemplo, si las mujeres son seleccionadas para desempeñar roles en ocupaciones de menor remuneración debido a estereotipos de género preestablecidos, esto puede ampliar la brecha salarial. En caso de que la brecha condicional persista, aún después de ajustar por variables observables, podríamos estar ante una combinación de discriminación estructural y diferencias ocupacionales no completamente reflejadas en el modelo.

## 5. Predicción del salario

En las secciones anteriores, se estimó algunas especificaciones teniendo en cuenta la inferencia. En esta sección, evaluaremos el poder predictivo de estas especificaciones.

### 5.1. División de la muestra

```{r}
# Semilla para consistencia de resultados
set.seed(10101) 

# Dividr la muestra en entrenamiento y prueba
sample_salario <- sample(c(TRUE, FALSE), nrow(df_salario), replace=TRUE, prob=c(0.7,0.3))

# Validación de la division de la muestra
sum(sample_salario)/nrow(df_salario)

# División en datos de training (70%) y test (30%)
train_sample  <- df_salario[sample_salario, ] 
test_sample   <- df_salario[!sample_salario, ]
```

El siguiente gráfico muestra como se distribuyen las observaciones entre el conjunto de entrenamiento y el de prueba

```{r}
# Crear el conjunto de datos para la gráfica
split_data <- data.frame(
  Split = c("Train", "Test"),
  Count = c(sum(sample_salario), sum(!sample_salario)),
  Percentage = c(sum(sample_salario)/length(sample_salario) * 100, sum(!sample_salario)/length(sample_salario) * 100)
)

# Crear el gráfico
ggplot(split_data, aes(x = Split, y = Count, fill = factor(Split))) + 
  geom_bar(stat = "identity", width = 0.5) + 
  geom_text(aes(label = paste0(round(Percentage, 1), "%\n(n=", Count, ")")),
            vjust = -0.5, color = "black", size = 4) + 
  labs(title = "Distribución de la división de la muestra de entrenamiento y prueba",
       y = "Número de observaciones",
       x = "") + 
  theme_bw() + 
  ylim(0, max(split_data$Count) * 1.2) + 
  scale_fill_manual(values = c("lightblue", "lightsalmon"))  
```

### 5.2 Comparación del rendimiento predictivo en términos de RMSE

Para realizar una comparación significativa de los rendimientos predictivos de los modelos anteriores, también se proponen cinco modelos adicionales que permitan identificar el mejor rendimiento incluyendo modelos no lienales y con mayor complejidad respecto a los estiamdos previamente. Por lo tanto, se tiene una totalidad de 8 modelos:

#### Modelo 1: Regresión con Female y controles

$$log(w) = β0 + β1Female + β2educ + β3tiempoempresa  +  β4age + u$$

#### Modelo 2: Regresión auxiliar (FWL - residuos de Female)

$$log(female) = β0 + β1educ + β2tiempoempresa  + β3age + u$$

#### Modelo 3: Regresión con residuos de Female

$$log(w) = β0 + β1residuosfemale + u$$

#### Modelo 4: Modelo sin controles (solo female)

$$log(w) = β0 + β1Female + β2tamañoempresa  + u$$

#### Modelo 5: Modelo con interacciones (female x age)

$$log(w) = β0 + β1Female + β2age + β3female*tiempoempresa + β4tiempoempresa + u$$

#### Modelo 6: Modelo no lineal con tamaño empresa²

$$log(w) = β0 + β1Female + β2tamaño_empresa + β3(tamañoempresa^2) + u$$

#### Modelo 7: Modelo con variables adicional e interaciones

$$log(w) = β0 + β1Female + β2educ + β3tiempoempresa + β4age + β5formal + β6segusocial + β7female*segusocial + β8(age^2) + u$$

#### Modelo 8:

$$log(w) = β0 + β1Female + β2educ + β3female*educ + β4age + β5(age^2) + u$$

```{r}
# Definición de modelos

# Modelo 1: Regresión con Female y controles
m1 <- lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                           data = train_sample)

# Modelo 2: Regresión auxiliar (FWL - residuos de Female)
m2 <- lm(female ~ max_nivel_educ + tiempo_empresa + age, 
                          data = train_sample)

train_sample$residuos_f_m2 <- residuals(m2)

# Modelo 3: Regresión con residuos de Female
m3 <- lm(log(salario_hora) ~ residuos_f_m2, data = train_sample)

# Modelo 4: Modelo sin controles (solo female)
m4 <- lm(log(salario_hora) ~ female + tamaño_empresa, data = train_sample)

# Modelo 5: Modelo con interacciones (female x age)
m5 <- lm(log(salario_hora) ~ female + age + female:tiempo_empresa + tiempo_empresa, data = train_sample)

# Modelo 6: Modelo no lineal con tamaño empresa²
m6 <- lm(log(salario_hora) ~ female + tamaño_empresa + I(tamaño_empresa^2), data = train_sample)

# Modelo 7: Modelo con variables adicional
m7 <- lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age + formal + segu_social + female:segu_social + I(age^2), 
                          data = train_sample)

# Modelo 8: 
m8 <- lm(log(salario_hora) ~ female + max_nivel_educ + female:max_nivel_educ + age + I(age^2), data = train_sample)

test_sample$residuos_f_m2 <- residuals(lm(female ~ max_nivel_educ + tiempo_empresa + age, data = test_sample))
```

Luego de definir los modelos, se procede con las respectivas predicciones, además de comparar los resultados del RMSE para identificar el modelo con el mejor rendimiento predictivo.

```{r}
# Generar predicciones y RMSE
pred_1 <- predict(m1, test_sample)
salario_1 <- RMSE(exp(pred_1), test_sample$salario_hora)

pred_2 <- predict(m2, test_sample)
salario_2 <- RMSE(exp(pred_2), test_sample$salario_hora)

pred_3 <- predict(m3, test_sample)
salario_3 <- RMSE(exp(pred_3), test_sample$salario_hora)

pred_4 <- predict(m4, test_sample)
salario_4 <- RMSE(exp(pred_4), test_sample$salario_hora)

pred_5 <- predict(m5, test_sample)
salario_5 <- RMSE(exp(pred_5), test_sample$salario_hora)

pred_6 <- predict(m6, test_sample)
salario_6 <- RMSE(exp(pred_6), test_sample$salario_hora)

pred_7 <- predict(m7, test_sample)
salario_7 <- RMSE(exp(pred_7), test_sample$salario_hora)

pred_8<- predict(m8, test_sample)
salario_8 <- RMSE(exp(pred_8), test_sample$salario_hora)

# Crear la tabla con los MSE
mse_table <- data.frame(
  Modelo = c("m1", "m2", "m3", "m4", "m5", "m6", "m7", "m8"),
  MSE = c(salario_1, salario_2, salario_3, salario_4, salario_5, salario_6, salario_7, salario_8)
)

# Imprimir la tabla
print(mse_table)
```

###5.c.i.ii. Discusión de los resultados de RMSE con Validation Set Approach

Se evaluaron ocho especificaciones diferentes usando Validation Set Approach para medir el rendimiento predictivo de los modelos con la métrica RMSE, la cual indica un mejor desempeño predictivo entre más bajo sea su nivel. El resultado hace evidente que el Modelo 7 tiene el menor valor de RMSE, con un valor de 13,448.67, por lo tanto, es el mejor en términos de RMSE. Esto sugiere que incluir controles adicionales como si la persona cuenta con seguridad social, si está en un trabajo formal, entre otros, aporta información relevante para predecir el cambio en los salarios.

El Modelo 7 tiene el mejor desempeño predictivo con un RMSE de 13,448.67. Esto es consistente con su mayor nivel de complejidad, ya que incorpora no solo los controles básicos, sino también términos adicionales como la variable formal, segu_social, la interacción female:segu_social y un término cuadrático I(age^2). El Modelo 1 sigue siendo un modelo competitivo, obteniendo el segundo mejor RMSE (13,604.31). Aunque es más simple que el Modelo 7, sigue capturando buena parte de la variabilidad del salario en función de female, max_nivel_educ, tiempo_empresa y age.

Los modelos con no linealidades e interacciones presentan mejoras en algunos casos, como el Modelo 8, que incorpora la interacción female:max_nivel_educ y logra un RMSE similar al Modelo 1 (13,644.11). El Modelo 2 es el peor en términos predictivos (RMSE = 16,113.97). Esto es esperado, ya que este modelo solo estima los residuos de female, sin utilizar directamente la variable dependiente log(salario_hora).

En términos generales, los modelos que incluyen mayores niveles de complejidad tienden a mejorar el desempeño predictivo, pero no todos los ajustes mejoran la precisión. La inclusión de interacciones y términos no lineales es útil solo si está bien justificada teóricamente.


###5.c.iii. Especificación del modelo con error de predicción: Modelo 7

```{r}
#Calculo errores de predicción
errores <- test_sample$salario_hora - exp(predict(m7, test_sample))

#Distribución de los errores
hist(errores, main = "Distribución de Errores de Predicción", 
     xlab = "Error de Predicción", col = "lightblue", border = "black")

#Identificar outliers en percentiles 2.5% y 97.5%
percentiles <- quantile(errores, probs = c(0.025, 0.975))
outliers <- test_sample[errores < percentiles[1] | errores > percentiles[2], ]

print(head(outliers))

#Datos más extremos y box plot outliers
boxplot(errores, main = "Boxplot de Errores de Predicción", col = "lightblue")
abline(h = percentiles, col = "red", lty = 2) # 


```
El histograma de errores de predicción muestra una distribución sesgada a la derecha, lo que indica que la mayoría de los errores son pequeños, pero existen algunas observaciones con diferencias extremadamente grandes entre el salario real y el predicho. El boxplot confirma la presencia de valores atípicos con errores de predicción elevados. Las líneas rojas en el gráfico representan los percentiles 2.5% y 97.5%, y cualquier punto fuera de este rango es considerado un outlier. Al analizar las características de los outliers, encontramos casos llamativos, como un individuo con un salario de 44444, que es significativamente mayor que el promedio. Otros outliers presentan salarios bajos que tampoco fueron bien predichos por el modelo. Estas diferencias pueden deberse a errores en la recolección de datos, condiciones laborales particulares o factores relevantes que no fueron incluidos en la regresión.

Desde el punto de vista de la DIAN, estos valores atípicos pueden indicar posibles irregularidades. Los individuos con ingresos extremadamente altos podrían estar no declarando información, lo que podría justificar una revisión adicional. También es posible que algunos outliers sean simplemente el resultado de errores en los datos, por lo que sería necesario verificar la calidad de la información. Otra posibilidad es que el modelo no haya capturado algunas características clave del mercado laboral, lo que explicaría por qué ciertas observaciones presentan errores tan grandes.

En conclusión, la DIAN podría enfocarse en analizar más a fondo los outliers para determinar si reflejan ingresos no declarados, errores en los datos o simplemente limitaciones del modelo. Para mejorar la precisión de las predicciones, sería recomendable incluir nuevas variables que expliquen mejor los salarios atípicamente altos o bajos. También sería útil realizar un análisis más detallado sobre la naturaleza de estos empleos y sus características tributarias, para evaluar si requieren una revisión adicional.


###5.d. Calculo de error predictivo con LOOCV

Los dos modelos con menor RMSE en el paso anterior fueron el modelo 1 y el modelo 7, a continuación, se realizará el análisis correspondiente.

Modelo 1 con LOOCV 

```{r}
ctrl <- trainControl(method = "LOOCV")

form_1 <- log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age

m1_loocv <- train(form_1, 
                  data = df_salario, 
                  method = 'lm', 
                  trControl = ctrl)

# Calcular RMSE en log
rmse_m1_loocv_real <- RMSE(exp(m1_loocv$pred$pred), exp(m1_loocv$pred$obs))

cat("Modelo 1 - LOOCV RMSE (Original):", round(rmse_m1_loocv_real, 2), "\n")
```

Modelo 7 con LOOCV

```{r}
ctrl <- trainControl(method = "LOOCV")

form_7 <- log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age + formal + segu_social + female:segu_social + I(age^2)

m7_loocv <- train(form_7,
                  data = df_salario,
                  method = 'lm', 
                  trControl= ctrl)

# Calcular RMSE en log
rmse_m7_loocv_real <- RMSE(exp(m7_loocv$pred$pred), exp(m7_loocv$pred$obs))

cat("Modelo 7 - LOOCV RMSE (Original):", round(rmse_m7_loocv_real, 2), "\n")

```

Modelo 1 con Leverage LOOCV 

```{r}
# Modelo 1 con LOOCV y leverage
m1_full <- lm(form_1, data = df_salario)

X_m1 <- model.matrix(m1_full)
y_m1 <- model.response(model.frame(m1_full))
beta_hat_m1 <- m1_full$coefficients
G_inv_m1 <- solve(t(X_m1) %*% X_m1)
vec_m1 <- 1 / (1 - hatvalues(m1_full))
N_m1 <- nrow(X_m1)
LOO_m1 <- numeric(N_m1)

for (i in 1:N_m1) {
  new_beta_m1 <- beta_hat_m1 - vec_m1[i] * G_inv_m1 %*% as.vector(X_m1[i, ]) * m1_full$residuals[i]
  new_error_m1 <- (y_m1[i] - (X_m1[i, ] %*% new_beta_m1))^2
  LOO_m1[i] <- new_error_m1
}

rmse_m1_loocv_laverage_real <- sqrt(mean((exp(y_m1) - exp(X_m1 %*% new_beta_m1))^2))
print(rmse_m1_loocv_laverage_real)

```

Modelo 7 con Leverage LOOCV 

```{r}
# Modelo 7 con LOOCV y leverage
m7_full <- lm(form_7, data = df_salario)

X_m7 <- model.matrix(m7_full)
y_m7 <- model.response(model.frame(m7_full))
beta_hat_m7 <- m7_full$coefficients
G_inv_m7 <- solve(t(X_m7) %*% X_m7)
vec_m7 <- 1 / (1 - hatvalues(m7_full))
N_m7 <- nrow(X_m7)
LOO_m7 <- numeric(N_m7)

for (i in 1:N_m7) {
  new_beta_m7 <- beta_hat_m7 - vec_m7[i] * G_inv_m7 %*% as.vector(X_m7[i, ]) * m7_full$residuals[i]
  new_error_m7 <- (y_m7[i] - (X_m7[i, ] %*% new_beta_m7))^2
  LOO_m7[i] <- new_error_m7
}

rmse_m7_loocv_laverage_real <- sqrt(mean((exp(y_m7) - exp(X_m7 %*% new_beta_m7))^2))
print(rmse_m7_loocv_laverage_real)

```

Tabla comparativa RMSE con diferentes metolodologías

```{r}
# Tabla de comparación
comparacion_rmse <- data.frame(
  Modelo = c("M1", "M7"),
  RMSE_VSA = c(
    sqrt(mean((exp(pred_1_log) - test_sample$salario_hora)^2)), 
    sqrt(mean((exp(pred_7_log) - test_sample$salario_hora)^2))
  ),
  RMSE_LOOCV = c(rmse_m1_loocv_real, rmse_m7_loocv_real),
  RMSE_Leverage = c(rmse_m1_loocv_laverage_real, rmse_m7_loocv_laverage_real)
)

print(comparacion_rmse)
```

Comparación del error predictivo entre Validation Set Approach y LOOCV

Se compararon los errores predictivos de los modelos M1 y M7 utilizando dos métodos de validación: el Validation Set Approach (VSA) y el Leave-One-Out Cross-Validation (LOOCV). Los resultados muestran que el RMSE obtenido con LOOCV es menor que el obtenido con el VSA para ambos modelos, lo que sugiere que la evaluación con LOOCV es más estable y menos dependiente de cómo se divida la muestra. En particular, el RMSE de M7 sigue siendo menor que el de M1 en ambos métodos, lo que refuerza la conclusión de que M7 tiene mejor desempeño predictivo.

Relación con la estadística de influencia (Leverage)

Los valores de RMSE calculados con LOOCV utilizando leverage muestran que las diferencias con el LOOCV tradicional son mínimas (por ejemplo, para M7, pasa de 12723.80 a 12721.74). Esto sugiere que las observaciones con alto leverage no están afectando significativamente la estabilidad del modelo en términos de error predictivo. En términos prácticos, esto implica que aunque algunas observaciones pueden tener un alto leverage, su impacto sobre la predicción global del modelo no es significativo. Si hubiera diferencias marcadas entre LOOCV normal y LOOCV con leverage, eso indicaría que ciertos puntos influyentes distorsionan la estimación de los coeficientes y, por ende, del error predictivo.

Conclusión

El modelo M7 sigue siendo el mejor en términos de error predictivo, independientemente del método de validación utilizado. Además, la inclusión de leverage en los cálculos de LOOCV confirma que no hay observaciones individuales que estén afectando de manera desproporcionada la estabilidad del modelo. Esto da confianza en la robustez de los resultados obtenidos.



# Referencias

1.  Pinedo, W. C., del Aguila, W. C., & Alvarado, G. D. P. P. (2022). Un análisis de la evasión tributaria.Ciencia Latina Revista Científica Multidisciplinar,6(2), 3224-3241.

2.  Pedro A. Cabra-Acela, 2021. “Premiar a los buenos contribuyentes, ¿un mecanismo efectivo? ” Documentos CEDE19419, Universidad de los Andes, Facultad de Economía, CEDE.

3.  Leopoldo Fergusson & Carlos Molina & Juan Felipe Riaño, 2017. "Evado impuestos, ¿y qué? Una nueva base de datos y evidencia de Colombia",Documentos CEDE15444, Universidad de los Andes, Facultad de Economía, CEDE.

4.  Díaz, D. & González, J. (2024).Controles tributarios y la evasión fiscal en Colombia. [Proyecto aplicado]. Repositorio Institucional UNAD. <https://repository.unad.edu.co/handle/10596/64465>

5.  Bloom Monterroza, C. C. y Villalba Ayazo, D. S. (2024). Causas y consecuencias de la evasión tributaria [Tesis de pregrado, Universidad Cooperativa de Colombia]. Repositorio Institucional Universidad Cooperativa de Colombia <https://hdl.handle.net/20.500.12494/57925>

6.  El déficit fiscal de 2024 superaría la meta del Marco Fiscal de Mediano Plazo y el ajuste requerido para 2025 es mayor que el contemplado en el decreto de aplazamiento, (CARF, 2024)

7.  Rocha Combita, J. (2024) Elusion y evasion fiscal en Colombia. <https://bibliotecadigital.iue.edu.co/jspui/handle/20.500.12717/3192>

8.  Cuervo Alvarado, M. (2022). Análisis de los determinantes de las asignaciones salariales entre hombres y mujeres en la industria manufacturera en Bogotá 2016-201

9.  Sabogal, A. (2012). Brecha salarial entre hombres y mujeres y ciclo económico en Colombia.
