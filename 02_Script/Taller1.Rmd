---
title: "T1_BDML"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-02-01"
output: html_document
---

# Problem set 1

## Introducción

La Dirección de Impuestos y Aduanas Nacionales (DIAN) constituye la principal fuente de ingreso del Gobierno Central, según lo señala el Comité Autónomo de la Regla Fiscal (2024). Este ingreso es esencial para sostener los recursos fiscales de la Nación. Sin embargo, la economía colombiana enfrenta un significativo desafío: un déficit fiscal alimentado, en parte, por ingresos tributarios que, acumulados hasta noviembre de 2024, se situaron 10,8 billones de pesos por debajo de las proyecciones establecidas en el Marco Fiscal de Mediano Plazo (MFMP). Este marco define los límites de gasto del gobierno y es crucial para la estabilidad financiera del país. 

González (2018) subraya la relevancia de la gestión de la DIAN en términos de control tributario y la utilización de diversas metodologías para combatir la evasión fiscal. Díaz y González (2024) añaden que una fiscalización efectiva depende de la implementación de instrumentos gerenciales, operativos, de medición y evaluación, capaces de identificar focos de evasión y contrabando. 

Diversos estudios apuntan a que el problema de la evasión fiscal se debe a factores como el bajo nivel educativo de los contribuyentes, la falta de valores, la desconfianza en el gobierno y la baja eficiencia en la administración de los recursos públicos (Pinedo, del Aguila y Alvarado, 2022). Según estos autores, contribuyentes financieramente responsables suelen compartir características como una cultura tributaria sólida, un alto nivel educativo y un ingreso familiar estable. 

Las medidas adoptadas por las instituciones para combatir la evasión fiscal son esenciales, especialmente en países en desarrollo donde esta práctica genera inequidad y desigualdad social. La evasión fiscal conduce a problemas como la baja recaudación de ingresos y el deterioro de las finanzas públicas, afectando la calidad de los servicios prestados por las entidades públicas. Un modelo de predicción de ingresos podría ser una herramienta útil para detectar casos de fraude y reducir esta brecha, además de identificar a personas y familias vulnerables que requieren asistencia. 

Este fenómeno distorsiona el sistema tributario, reduce los ingresos destinados al financiamiento del gasto público y afecta la capacidad del gobierno para sostener programas esenciales en áreas clave como salud, educación e infraestructura. Además, la evasión fiscal genera inequidad, compromete la competitividad del país y puede impactar negativamente el desarrollo socioeconómico nacional. Al mismo tiempo la evasión fiscal trae consigo consecuencias negativas en la competitividad del país al desfavorecer a los empresarios que cumplen con sus obligaciones tributarias (Yikona, 2011).  

Estudios como los de Espitia y Suárez (2017) y Rojas, Martínez, Álvarez y Farfán (2024) destacan cómo la evasión fiscal afecta la competitividad y contribuye al déficit fiscal, lo que puede llevar a una crisis financiera. La evasión fiscal es más frecuente en lugares con una alta informalidad laboral, donde los individuos son menos educados y con escasos recursos, lo que dificulta la recaudación efectiva de impuestos, reflejando una falta de confianza en el sistema y las instituciones. (Leopoldo Fergusson & Carlos Molina & Juan Felipe Riaño, 2017) 

El presente trabajo se enfocará en la estimación de un modelo econométrico basado en datos de la Gran Encuesta Integrada de Hogares de 2018, realizada por el Departamento Administrativo Nacional de Estadística para Bogotá. Se analizarán las condiciones salariales de la población mayor de 18 años, utilizando diferentes métodos para predecir sus ingresos. La estructura del trabajo incluirá la descripción y limpieza de datos, el análisis de variables, la predicción de ingresos y las conclusiones y limitaciones del estudio. 


## Data

2. Descripción de los Datos y Proceso de Limpieza 

2.1 Proceso de adquisición de los datos 

En la presente sección se realiza una descripción de los datos y el proceso de adquisición y limpieza obtenidos en la Gran Encuesta Integrada de Hogares (GEIH) para 2018, realizada por el Departamento Administrativo Nacional de Estadística para Bogotá del "Informe de Pobreza Monetaria y Desigualdad". Esta sección se enfoca en las personas empleadas mayores de dieciocho (18) años. 

La GEIH proporciona información estadística del tamaño y estructura de la fuerza laboral, incluyendo datos sobre empleo, desempleo y población fuera de la fuerza de trabajo, los ingresos laborales y no laborales de los hogares, y la pobreza monetaria y extrema de la población residente en el país. Esta encuesta permite caracterizar a la población según sexo, edad, parentesco con el jefe del hogar, nivel educativo, afiliación al sistema de seguridad social en salud, grupos poblacionales y otras formas de trabajo, como producción de bienes y servicios para autoconsumo y trabajo en formación, entre otros. 

La GEIH tiene una muestra anual aproximada de 315,000 hogares a nivel nacional, lo que le confiere una mayor cobertura y permite generar indicadores más confiables para los principales indicadores del mercado laboral. 

La base de datos se encuentra almacenada en una página web, por lo que se realizó un scrap del sitio web https://ignaciomsarmiento.github.io/GEIH2018_sample/. En primer lugar, se exploró la URL para identificar la información almacenada, evidenciando que se encontraba dividida en 10 data chunks. Se inspeccionó cada una de ellas y se realizó una iteración para consolidar la información de cada tabla y crear un dataframe llamado df_GEIH con 32.177 observaciones con 178 variables. 

## Modelo de salario individual por hora

### Configuración inicial del ambiente

Para llevar a cabo el análisis, utilizamos "pacman" para facilitar la carga e instalación de varios paquetes en R que permiten la recolección, manipulación, exploración y visualización de datos. Así mismo, utilizaremos "p_load( )" para instalar y cargar multiples paquetes en unsa sola línea de codigo como se muestra a continuación:

```{r}
if(!require(pacman)) install.packages("pacman") ; require(pacman)

p_load(rvest,     # permite realizar web scraping en R
       dplyr,     # Permite manipulación y transformación de los datos
       skimr,     # resumen estadístico
       visdat,    # visualización de missing values
       corrplot,  # correlation plots
       stargazer, # Tables/outputs to tex
       ggplot2,    # graficación
       boot
       )
```

### Carga e inspección de los datos

#### 1. Proceso de carga de datos

LAU

```{r}
# Lista tablas
todas_las_tablas <- list()

# Iterar en las 10 paginas
for (i in 1:10) {
  url_tabla <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", i, ".html")
  
  pagina_tabla <- read_html(url_tabla)
  
  # Extraer tabla
  tabla <- pagina_tabla %>% html_element("table") %>% html_table()
  
  # Agregar la tabla a la lista
  todas_las_tablas[[i]] <- tabla
}

# Unir todas las tablas en un solo dataframe
df_GEIH <- bind_rows(todas_las_tablas)
```

#### 2. Proceso de inspección

2.2 Proceso de limpieza de los datos 

En primer lugar, se filtraron las personas ocupadas mayores de 18 años utilizando las variables "ocu" y "age". El término de personas ocupadas hace referencia a aquellos individuos que están trabajando en alguna actividad económica, ya sea de manera formal o informal, y que se encuentran dentro de la edad laboral. Para este análisis, se consideró que la edad legal para trabajar en Colombia es de 18 años, a partir de la cual no se aplican las restricciones que rigen para los menores de edad. 

Lo anterior fue el resultado de la exploración de los datos, en la que se identificaron variables similares, como "ocu" y "dsi". Ambas son variables dicotómicas: "dsi" toma el valor de 1 si la persona está desempleada y 0 en caso contrario, mientras que "ocu" toma el valor de 1 si la persona está ocupada y 0 si no lo está. Dado que nuestro análisis se enfoca en las personas que están trabajando, se eligió la variable "ocu", ya que permite estudiar específicamente a las personas ocupadas. De este filtro, se da como resultado una base de datos con 16.542 observaciones con 178 variables.  

Se procedió a identificar los datos faltantes. Para algunas variables, se utilizó el promedio de los valores disponibles, lo que resultó en una nueva base de datos denominada “df_salario” con 16,542 observaciones y 10 variables. Posteriormente, se calcularon los porcentajes de valores faltantes por cada variable y se graficó la distribución de estos porcentajes. 

En cuanto a la imputación de los valores faltantes, se abordó de acuerdo con el tipo de variable. Para las variables categóricas, como educación y seguridad social, se ordenaron de manera descendente y se calculó el valor más común en cada categoría, que fue utilizado para reemplazar los datos faltantes. 

Para la imputación de la variable continua, salario por hora, se analizó su distribución mediante un gráfico, observándose que presenta una cola hacia la derecha. Debido a esta distribución, se optó por imputar los valores faltantes con la mediana, ya que representa mejor el valor central de los datos. Finalmente, se verificó que no quedaran valores faltantes en la base de datos. 

```{r}
# Resumen de la Base de datos df_GEIH
skim(df_GEIH) %>% head()

df_GEIH %>%
  select(age, ocu) %>%  # Visualizar solo las columnas clave
  sample_n(10)  # Mostrar 10 filas aleatorias

# Verificar estructura de las variables clave
str(df_GEIH[, c("age", "ocu")])

# Filtrar personas mayores de 18 años que están empleadas
df_filtrado <- df_GEIH %>%
  filter(age >= 18, ocu == 1) 

head(df_filtrado)

# Limpieza de datos 
```

## Elección de varibles y valores faltantes

#### 1. Elección de variables

Se crea un nuevo data frame para con algunas de las variables que hacen parte de la GEIH, con el objetivo de explicar el salario por hora de una persona. A continuación se explican las variables elegidas y su pertinencia para la estimación del modelo.

- Y_total_m_ha (Ingreso total mensual): Esta variable es la independiente y capta el salario total mensual que recibe un trabajador, que es directamente el objeto de análisis en estudios de salarios. 

- Age (Edad): La edad influye en los salarios, ya que está vinculada a la experiencia laboral y las habilidades adquiridas a lo largo del tiempo. En general, la relación entre edad y salario es positiva hasta cierto punto, ya que la experiencia suele traducirse en mayores ingresos. Sin embargo, en etapas más avanzadas, esta relación puede estabilizarse o incluso disminuir. Según X, los jóvenes enfrentan tasas de desempleo más altas en el mercado laboral, mientras que las personas de mayor edad suelen experimentar períodos de desempleo más cortos, pero con una duración más prolongada. Orlando, A. (2000). DNP. 

- Sex (Género): Esta variable es una dummy que toma el valor de 1 si la persona es mujer y 0 si es hombre. Su relevancia radica en el análisis de las diferencias salariales entre géneros. En numerosos estudios económicos, se ha observado la existencia de una brecha salarial de género, donde, en promedio, las mujeres ganan menos que los hombres por realizar el mismo trabajo o tareas similares. La teoría de discriminación laboral de Joan Robinson (1933) sostiene que, aunque hombres y mujeres sean igualmente productivos, las mujeres recibirán un salario inferior debido a que la curva de oferta laboral femenina es menos elástica que la masculina. (Cuervo Alvarado, M., 2022). 

- MaxEducLevel (Máximo nivel educativo): El nivel educativo es una variable clave que afecta el salario. Los individuos con mayor nivel educativo suelen tener acceso a trabajos mejor remunerados debido a que se asocia con mayor capital humano, habilidades y capacidades técnicas como lo define la teoría planteada por Becker (1964)  

- P6426 (Tiempo en la empresa): Esta variable se refiere al número de años que una persona ha trabajado en la misma organización. Puede estar relacionada con el aumento salarial por antigüedad. Según Gary Becker y Robert E. Lucas Jr., el capital humano abarca las habilidades y cualidades que hacen a las personas más productivas, siendo así un motor clave para el desarrollo organizacional. Este capital se convierte en una ventaja fundamental para las empresas, permitiéndoles desempeñarse eficazmente en su entorno. (Cuervo Alvarado, M., 2022). 

- P6870 (Tamaño de la empresa): El tamaño de la empresa es una variable clave en la determinación salarial. Según Cuervo Alvarado (2022), las pequeñas empresas, que emplean de 1 a 10 personas, son determinantes en el tamaño y la producción de la industria. Sin embargo, en general, las empresas más grandes tienen una mayor capacidad económica, lo que les permite ofrecer salarios más altos y proporcionar mejores compensaciones a sus empleados. 

- Depto (Departamento): El departamento o área de trabajo de un empleado puede influir en el salario. Diferentes departamentos tienen diferentes niveles de remuneración, dependiendo de la especialización, la demanda de las habilidades y el tipo de trabajo realizado. 

- Formal (Formalidad del empleo): Según Orlando (2000), en su informe del DNP, la formalidad del empleo se refiere a si el trabajador está registrado formalmente o si trabaja en la informalidad. Los trabajos formales suelen tener mejores salarios, beneficios y seguridad social, mientras que los trabajos informales presentan salarios más bajos y menor estabilidad. 

- P6100 (Seguridad social): La Organización Internacional del Trabajo hace referencia al régimen al que un trabajador está afiliado dentro del sistema de salud. El acceso a la seguridad social, especialmente a través de los diferentes regímenes (contributivo, especial y subsidiado), está estrechamente vinculado con la estabilidad económica y las oportunidades de ingresos. 

```{r}
# Nuevo data frame
df_salario <- df_filtrado %>%
  select(y_total_m_ha, age, ocu, sex, maxEducLevel, p6426, p6870, depto, formal, p6100)

# cambio del nombre de algunas variables
df_salario <-  df_salario %>% 
  rename(salario_hora = y_total_m_ha,
         max_nivel_educ = maxEducLevel,
         tiempo_empresa = p6426,
         tamaño_empresa = p6870,
         segu_social = p6100
         )

# estadísticas de df_salario
skim(df_salario)
str(df_salario)
  
```

Así mismo, para poder trabjar con los datos de forma adecuda, es necesario realizar un análisis descirptivo de las variables seleccionadas como se muestra a continuación:

-   Tipos de datos:

    -   Numeric:

    -   Interger:

-   Estadísticas descriptivas por variables: (describir si tiene missing values, media, complete_rate, desviación estándar, cuartiles)

    -   salario_hora:

    -   age:

    -   ocu:

    -   sex:

    -   max_nivel_educ:

    -   tiempo_empresa:

    -   tamaño_empresa:

    -   depto:

    -   formal:

    -   segu_social:

#### 2. Valores faltantes

Con el resumen de estadísticas del nuevo data frame creado, se identifica la cantidad de valores faltantes (n_missing) en las variables salario_hora, segu_social y max_nivel_educ. A continuación, se procede a validar la información e imputar los valores faltantes de acuerdo a las caracterísitcas de las variables para poder estimar los modelos más adelante.

```{r}
# datos faltantes con skim
base_faltantes <- skim(df_salario) %>% select( skim_variable, n_missing)

# calcular el porcentaje de valores faltantes
obs <- nrow(df_salario) 

base_faltantes<- base_faltantes %>% mutate(p_missing = n_missing/obs)
head(base_faltantes)

# ordenar de forma descendente
base_faltantes <- base_faltantes %>% arrange(-n_missing)

# mantener solo las variables con valores faltantes
base_faltantes<- base_faltantes %>% filter(n_missing!= 0)
base_faltantes

# gráfica de los valores faltantes
ggplot(base_faltantes, aes(x = reorder(skim_variable, -n_missing), y = p_missing, fill = skim_variable)) +
  geom_bar(stat = "identity", color = "black", width = 0.5) +  
  scale_y_continuous(labels = scales::percent) +  
  scale_fill_manual(values = c("lightsalmon", "lightpink", "lightblue")) +  
  labs(title = "Porcentaje de valores faltantes por variables", 
       x = "Variables",
       y = "Porcentaje de valores faltantes") + 
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1))

# Imputación de valores faltantes con el Método 1: Media/Mediana

## Imputación de variables categóricas: max_nievl_educ y segu_social

### Calcular los valores mas comunes
educacion <- as.numeric(names(sort(table(df_salario$max_nivel_educ), decreasing = TRUE)[1]))

seg_soc <- as.numeric(names(sort(table(df_salario$segu_social), decreasing = TRUE)[1]))

### Imputación de los valores faltantes para ambas variables
df_salario <- df_salario  %>%
  mutate(max_nivel_educ = ifelse(is.na(max_nivel_educ) == TRUE, educacion , max_nivel_educ)) %>% 
  mutate(segu_social = ifelse(is.na(segu_social) == TRUE, seg_soc , segu_social))

## Imputación de variable continua: salario por hora

### Gráfica de la distribución del salario por hora
ggplot(df_salario, aes(salario_hora)) +
  geom_histogram(color = "#000000", fill = "#0099F8") +
  geom_vline(xintercept = median(df_salario$salario_hora, na.rm = TRUE), linetype = "dashed", color = "red") +
  geom_vline(xintercept = mean(df_salario$salario_hora, na.rm = TRUE), linetype = "dashed", color = "blue") +  
  ggtitle(" Ingreso Total por hora") +
  theme_classic() +
  theme(plot.title = element_text(size = 18))

#### Debido a que la distribución del ingreso total por hora tiene un cola a la derecha, se deicide utilizar la mediana para imputar los valores faltantes.

### Imputación de valores faltantes para variable continua
df_salario <- df_salario %>% 
  mutate(salario_hora = ifelse(is.na(salario_hora) == TRUE, median(df_salario$salario_hora, na.rm = TRUE) , salario_hora))

# Validación de la correcta imputación de valroes faltantes en el data frame de salario
sum(is.na(df_salario))
```

## 3. Perfil de edad-salario

Una gran cantidad de evidencia en economía laboral sugiere que el perfil de edad-salario del trabajador típico tiene una trayectoria predecible: “Los salarios tienden a ser bajos cuando el trabajador es joven; aumentan a medida que el trabajador envejece, alcanzando un máximo alrededor de los 50 años; y la tasa salarial tiende a permanecer estable o a disminuir ligeramente después de los 50 años”.
En esta subsección vamos a estimar el perfil de edad-salario para los individuos de esta muestra:

$$
log(w) = β1 + β2Age + β3Age2 + u	(2)
$$

```{r}
#Estimacion de regresion log (salario)
modelo_age_wage <- lm(log(salario_hora) ~ age + I(age^2), data = df_salario) 

summary(modelo_age_wage)

```

# Interpretación de los resultados de la regresión log (salario)
Coeficientes: El intercepto indica un valor de 7.735 del logaritmo del salario cuando la edad es cero, algo que en terminos de interpretación no tiene un sentido práctico. El coeficiente de edad muestra como cambia el logaritmo del salario con cada año adicional de edad. En este caso por cada año adicional de edad el salario aumenta 4.6%. El coeficiente de edad^2 refleja el efecto cuadrático de la edad. En este caso el valor es negativo, lo que indicaría que el salario aumenta hasta cierto punto y luego comienza a disminuir. Este valor se va a determinar en el analisis de "edad pico" para evaluar en que punto se produce el cambio. 

Significación: Según los resultados obtenidos en la regresión todos los coeficientes obtenidos son estadisticamente significativos al 0.01 (99%). 

Bondad de ajuste: El R² es  0.0194 y R² ajustado da el valor de 0.01932 , esto indica que el modelo explica el salario en un 1.93%. Estos valores bajores indican que el modelo captura una parte de la relación y existen otros factores que afectan el logaritmo de salario no incluidos en el modelo. 

```{r}
# Gráfico del perfil estimado de ingresos y edad

edades <- unique(df_salario$age)  

# Calcular los log salarios predichos por edad
log_salarios_predichos <- coef(modelo_age_wage)["(Intercept)"] +
                          coef(modelo_age_wage)["age"] * edades +
                          coef(modelo_age_wage)["I(age^2)"] * edades^2

# Data frame con salario log y reales
df_pred <- data.frame(
  edad = edades,
  log_salario = log_salarios_predichos,
  salario = exp(log_salarios_predichos)  
)

# Graficar el perfil estimado de ingresos y edad
ggplot(df_pred, aes(x = edad, y = salario)) +
  geom_line(color = "blue", size = 1) +
  geom_point(data = df_pred %>% filter(edad %% 10 == 0),  
             aes(x = edad, y = salario), color = "red", size = 2) +  # Puntos cada 10 años
  labs(title = "Perfil estimado de ingresos por hora según la edad",
       x = "Edad",
       y = "Salario promedio estimado") +
  theme_minimal()


```

 # Análisis de la “edad pico” con sus respectivos intervalos de confianza.
 

```{r}
# Bootstrap para construir los intervalos de confianza

set.seed(123)
repeticiones <- 1000 #Cantidad de repeciones
betas_repeticiones <- rep(NA, repeticiones) #Vector donde se almacenará las estimaciones

for (i in 1:repeticiones){
  boot1 <- sample(df_salario$age, 1000, replace=TRUE) #Remuestreo aleatorio edad
  boot2 <- sample(df_salario$salario_hora, 1000, replace = TRUE) #Remuestreo aleatorio Salario
  m_boot <- data.frame (boot2, boot1) #Crear un data frame con las dos muestreas
  modelo_boot1 <- lm(formula = log(boot2) ~ boot1 + I(boot1^2), data = m_boot) #Calculo de los nuevos coeficientes
  betas_boot1 <- modelo_boot1$coefficients [1] #Seleccion de los nuevos betas con bootstrap
  betas_repeticiones[i] <- betas_boot1 #Almanecamiento de los nuevos betas
}

#Calcular los cuantiles de confianza de la matriz
quantiles_boot <- quantile(betas_repeticiones, probs = c(0.025,0.975))

#Ver los resultados de los cuantiles en la variable age.
quantiles_boot

#Graficar el histograma

hist(betas_repeticiones, las=1,
     main = "Distribución de muestra",
     xlim = c(7.5,9.5),
     xlab = "Betas",
     ylim = c(0,200),
     ylab = "Frecuencia",
     col = "blue")

abline(v=quantiles_boot, col = "green", lwd =2, lty=2)
legend("topright", legend = "Cuantiles", col = "green", lwd = 2, lty = 2)

#-----

#https://rpubs.com/andrew32118/Bootstrap

# Realizar el remuestreo (bootstrap) de tamaño 1000 con reemplazos sobre la variable age
boot <- sample(df_salario$age,1000, replace = TRUE)

#Crear una matriz de 1000 filas y 1 columna a partir del remuestreo
m_boots <- matrix(boot, nrow = 1000, ncol = 1, byrow = TRUE)

#Calcular los cuantiles de confianza de la matriz
quantiles <- quantile(m_boots, probs = c(0.025,0.975))

#Ver los resultados de los cuantiles en la variable age.
quantiles

#Calcular los intervalos de confianza de la matriz
intervalos <- c(2*mean(m_boots)-quantiles[2], 2*mean(m_boots)-quantiles[1])

#Ver los resultados de los intervalos en la variable age.
intervalos

#Graficar el histograma

hist(m_boots, las=1,
     main = "Distribución de muestra",
     xlim = c(0,100),
     xlab = "Edades",
     ylim = c(0,200),
     ylab = "Frecuencia",
     col = "blue")

abline(v=intervalos, col = "red", lwd = 2, lty = 2)
abline(v=quantiles, col = "green", lwd =2, lty=2)
legend("topright", legend = c("Intervalos", "Cuantiles"), col = c("red","green"), lwd = 2, lty = 2)

```

## 4.La brecha salarial de género. 

Los responsables de las políticas se han preocupado durante mucho tiempo por la brecha salarial de género.

$$
log(w) = β1 + β2Female + u
$$
donde Female es un indicador que toma uno si el individuo en la muestra se identifica como mujer.

```{r}
#Se crea la variable female en nuestra base

df_salario <- df_salario %>%
              mutate(female = ifelse(sex == 0, 1, 0))

#Estimación de regresion log (salario) con female
reg_female <- lm(formula = log(salario_hora) ~ female, data =df_salario)

stargazer(reg_female, type = "text")

```
*Interpretación
- Significancia global: El modelo es significativo al 0,01 (99%), es decir, la variable del modelo explica el salario por hora.

- Bondad de ajuste: El R² es  0.002 y R² ajustado da el valor de 0.002 , esto indica que el modelo explica el salario en un 0.2%

- El error estandar para este modelo es de0.787 y esto indica la dispersión entre las 16542 observaciones y la estimación.

- Significancia parcial: La variable female es significativa al 0.01 (99%), el error estandar es de 0.012 y explica que si es mujer, en promedio el salario disminuye en 7.9%


## 4.1 Salario igual para trabajos iguales?

El eslogan "salario igual por trabajo igual" es una forma de interpretar que los empleados con características laborales similares, no debe existir ninguna brecha salarial de genero.  En esta sección, se utilizará el modelo Frisch-Waugh-Lovell (FWL) para estimar la brecha salarial condicional, incorporando variables de control que reflejan las características semejantes de los trabajadores y los puestos de trabajo. El procedimiento se divide en tres pasos, que se describen a continuación:

Paso 1: Estimación de la regresión con todos los predictores completos, y cálculo de los residuos u.
Paso 2: Se realiza una regresión auxiliar utilizando los residuos obtenidos en el paso anterior.
Paso 3: El Teorema de Frisch-Waugh-Lovell establece que los residuos de la primera y segunda regresión son numéricamente equivalentes.

```{r}
# PASO 1
# Estimación de regresion log (salario) con female y otros controles
reg_female_controles <- lm(formula = log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                          data =df_salario)

# PASO 2
# Regresión auxiliar para obtener los residuos u
reg_female_residuos <- lm(formula = female  ~ max_nivel_educ + tiempo_empresa + age, 
                          data =df_salario)

residuos_female <- residuals(reg_female_residuos)

# PASO 3
#Correr la primera regresión con los residuos de female 
reg_residuos_female <- lm(log(salario_hora) ~ residuos_female, data = df_salario)


stargazer(reg_female_controles , reg_residuos_female, type = "text")
```
De los resultados de las regresiones se puede observar que el teorema FWL se cumple porque los coeficientes de los betas son iguales

```{r}
#Se comparan los coeficientes de female

beta_female_controles <- coef(reg_female_controles)["female"]
beta_femal_residuos <- coef(reg_residuos_female)["residuos_female"]

beta_female_controles 
beta_femal_residuos
```
Posteriomente, se estima el modelo FWL con Boostrap 
```{r}
# Función para sacar residuales
fwl_boot <- function(data ,index) {
  
          coef(lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                          data = df_salario, 
                          subset = index))[2]
               }

# Validación
fwl_boot(df_salario, 1:nrow(df_salario))
  
# Semilla para hacerlo reproducible
set.seed(123)

# Estimaciones y errores estandar
errorestandar_boot <-  boot(df_salario, fwl_boot, R = 1000)
errorestandar_boot

```

Análisis de comparación de las estimaciones y los errores estándar

Al comparar las estimaciones de los coeficientes para female en los dos modelos (uno con controles y otro con los residuos de female), se observa que las estimaciones son prácticamente iguales cuando se utiliza el bootstrap. Sin embargo, los errores estándar son ligeramente diferentes entre los métodos con FWL y FWL con Boostrap. En el modelo estimado mediante el método FWL, el error estándar para female es de 0.011, mientras que en el modelo ajustado por los residuos de female, el error estándar aumenta ligeramente a 0.012. Aunque ambos valores son bastante similares, el modelo con los residuos refleja un pequeño aumento en la variabilidad de la estimación.

El valor del error estándar de la estimación de female mediante el método FWL con bootstrap es 0.01096617, lo que es consistente con los resultados obtenidos en el modelo con controles. Además, se observa que la variabilidad en la estimación de female es más baja en el modelo con bootstrap, en comparación con el modelo FWL ajustado por los residuos, lo que sugiere una mayor precisión en las estimaciones obtenidas mediante el bootstrap.

A pesar de estos pequeños cambios en los errores estándar, la brecha salarial de género sigue siendo evidente. El coeficiente negativo para female en ambos modelos indica que las mujeres ganan, en promedio, menos que los hombres, lo que confirma la persistencia de la brecha salarial.


Ahora, se graficará el perfil de edad- salario previsto y se calculará las edades pico implícitas con los respectivos intervalos de confianza por género
```{r}
ggplot(df_salario) + 
  geom_point(
    aes(x = age, y = log(salario_hora)),
    color = "darkred", size = 2
  ) + 
  labs(
    title = "Relación de edad y Salario por Horas",
    x = "Edad",
    y = "Ln Salario por horas"
  ) +
  theme_bw()

```




# Referencias 

1. Pinedo, W. C., del Aguila, W. C., & Alvarado, G. D. P. P. (2022). Un análisis de la evasión tributaria.Ciencia Latina Revista Científica Multidisciplinar,6(2), 3224-3241. 

2. Pedro A. Cabra-Acela, 2021. “Premiar a los buenos contribuyentes, ¿un mecanismo efectivo? ” Documentos CEDE19419, Universidad de los Andes, Facultad de Economía, CEDE. 

3. Leopoldo Fergusson & Carlos Molina & Juan Felipe Riaño, 2017. "Evado impuestos, ¿y qué? Una nueva base de datos y evidencia de Colombia",Documentos CEDE15444, Universidad de los Andes, Facultad de Economía, CEDE.  

4. Díaz, D. & González, J. (2024).Controles tributarios y la evasión fiscal en Colombia. [Proyecto aplicado]. Repositorio Institucional UNAD. https://repository.unad.edu.co/handle/10596/64465 

5. Bloom Monterroza, C. C. y Villalba Ayazo, D. S. (2024). Causas y consecuencias de la evasión tributaria [Tesis de pregrado, Universidad Cooperativa de Colombia]. Repositorio Institucional Universidad Cooperativa de Colombia https://hdl.handle.net/20.500.12494/57925 

6. El déficit fiscal de 2024 superaría la meta del Marco Fiscal de Mediano Plazo y el ajuste requerido para 2025 es mayor que el contemplado en el decreto de aplazamiento, (CARF, 2024) 

7. Rocha Combita, J. (2024) Elusion y evasion fiscal en Colombia. https://bibliotecadigital.iue.edu.co/jspui/handle/20.500.12717/3192 

8. Cuervo Alvarado, M. (2022). Análisis de los determinantes de las asignaciones salariales entre hombres y mujeres en la industria manufacturera en Bogotá 2016-201 