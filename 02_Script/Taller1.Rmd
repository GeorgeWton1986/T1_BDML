---
title: "T1_BDML"
author: GARCIA BERNAL, ZAIRA ALEJANDRA RIVERA SANABRIA, LAURA SARIF JACOME VELASCO,
  NICOLAS VIAFARA MORALES, JORGE ELIECER
date: "2025-02-01"
output: html_document
---

# Problem set 1:Modelo de salario individual por hora

## 1. Introducción

La Dirección de Impuestos y Aduanas Nacionales (DIAN) constituye la principal fuente de ingreso del Gobierno Central, según lo señala el Comité Autónomo de la Regla Fiscal (2024). Este ingreso es esencial para sostener los recursos fiscales de la Nación. Sin embargo, la economía colombiana enfrenta un significativo desafío: un déficit fiscal alimentado, en parte, por ingresos tributarios que, acumulados hasta noviembre de 2024, se situaron 10,8 billones de pesos por debajo de las proyecciones establecidas en el Marco Fiscal de Mediano Plazo (MFMP). Este marco define los límites de gasto del gobierno y es crucial para la estabilidad financiera del país.

González (2018) subraya la relevancia de la gestión de la DIAN en términos de control tributario y la utilización de diversas metodologías para combatir la evasión fiscal. Díaz y González (2024) añaden que una fiscalización efectiva depende de la implementación de instrumentos gerenciales, operativos, de medición y evaluación, capaces de identificar focos de evasión y contrabando.

Diversos estudios apuntan a que el problema de la evasión fiscal se debe a factores como el bajo nivel educativo de los contribuyentes, la falta de valores, la desconfianza en el gobierno y la baja eficiencia en la administración de los recursos públicos (Pinedo, del Aguila y Alvarado, 2022). Según estos autores, contribuyentes financieramente responsables suelen compartir características como una cultura tributaria sólida, un alto nivel educativo y un ingreso familiar estable.

Las medidas adoptadas por las instituciones para combatir la evasión fiscal son esenciales, especialmente en países en desarrollo donde esta práctica genera inequidad y desigualdad social. La evasión fiscal conduce a problemas como la baja recaudación de ingresos y el deterioro de las finanzas públicas, afectando la calidad de los servicios prestados por las entidades públicas. Un modelo de predicción de ingresos podría ser una herramienta útil para detectar casos de fraude y reducir esta brecha, además de identificar a personas y familias vulnerables que requieren asistencia.

Este fenómeno distorsiona el sistema tributario, reduce los ingresos destinados al financiamiento del gasto público y afecta la capacidad del gobierno para sostener programas esenciales en áreas clave como salud, educación e infraestructura. Además, la evasión fiscal genera inequidad, compromete la competitividad del país y puede impactar negativamente el desarrollo socioeconómico nacional. Al mismo tiempo la evasión fiscal trae consigo consecuencias negativas en la competitividad del país al desfavorecer a los empresarios que cumplen con sus obligaciones tributarias (Yikona, 2011).

Estudios como los de Espitia y Suárez (2017) y Rojas, Martínez, Álvarez y Farfán (2024) destacan cómo la evasión fiscal afecta la competitividad y contribuye al déficit fiscal, lo que puede llevar a una crisis financiera. La evasión fiscal es más frecuente en lugares con una alta informalidad laboral, donde los individuos son menos educados y con escasos recursos, lo que dificulta la recaudación efectiva de impuestos, reflejando una falta de confianza en el sistema y las instituciones. (Leopoldo Fergusson & Carlos Molina & Juan Felipe Riaño, 2017)

El presente trabajo se enfocará en la estimación de un modelo econométrico basado en datos de la Gran Encuesta Integrada de Hogares de 2018, realizada por el Departamento Administrativo Nacional de Estadística para Bogotá. Se analizarán las condiciones salariales de la población mayor de 18 años, utilizando diferentes métodos para predecir sus ingresos. La estructura del trabajo incluirá la descripción y limpieza de datos, el análisis de variables, la predicción de ingresos y las conclusiones y limitaciones del estudio.

## 2. Datos

### (a) Descripción de los datos

En la presente sección se realiza una descripción de los datos y el proceso de adquisición y limpieza obtenidos en la Gran Encuesta Integrada de Hogares (GEIH) para 2018, realizada por el Departamento Administrativo Nacional de Estadística para Bogotá del "Informe de Pobreza Monetaria y Desigualdad". Esta sección se enfoca en las personas empleadas mayores de dieciocho (18) años.

La GEIH proporciona información estadística del tamaño y estructura de la fuerza laboral, incluyendo datos sobre empleo, desempleo y población fuera de la fuerza de trabajo, los ingresos laborales y no laborales de los hogares, y la pobreza monetaria y extrema de la población residente en el país. Esta encuesta permite caracterizar a la población según sexo, edad, parentesco con el jefe del hogar, nivel educativo, afiliación al sistema de seguridad social en salud, grupos poblacionales y otras formas de trabajo, como producción de bienes y servicios para autoconsumo y trabajo en formación, entre otros.

La GEIH tiene una muestra anual aproximada de 315,000 hogares a nivel nacional, lo que le confiere una mayor cobertura y permite generar indicadores más confiables para los principales indicadores del mercado laboral.

### (b) Proceso de adquisición de los datos

#### Configuración inicial del ambiente de trabajo

Para llevar a cabo el análisis, utilizamos "pacman" para facilitar la carga e instalación de varios paquetes en R que permiten la recolección, manipulación, exploración y visualización de datos. Así mismo, utilizaremos "p_load( )" para instalar y cargar multiples paquetes en unsa sola línea de codigo como se muestra a continuación:

```{r}
if(!require(pacman)) install.packages("pacman") ; require(pacman)

p_load(rvest,     # Permite realizar web scraping en R
       dplyr,     # Permite manipulación y transformación de los datos
       skimr,     # Resumen estadístico
       visdat,    # Visualización de missing values
       corrplot,  # Correlation plots
       stargazer, # Tables/outputs to tex
       ggplot2,   # Graficación
       scales,    # Formato de números para gráficas
       boot,      # Permite aplicar bootstrap
       tidyverse, # Análisis y tranformación de datos
       caret      # Predicción de modelos
       )
```

#### Proceso de extracción de datos

La base de datos se encuentra almacenada en una página web, por lo que se realizó scrapping del sitio web <https://ignaciomsarmiento.github.io/GEIH2018_sample/>. En primer lugar, se exploró la URL para identificar la información almacenada, evidenciando que se encontraba dividida en 10 data chunks. Se inspeccionó cada una de ellas y se realizó una iteración para consolidar la información de cada tabla y crear un dataframe llamado df_GEIH con 32.177 observaciones con 177 variables.

En el proceso de extraccción, se emplea el paquete `rvest` para analizar el contenido de la página web y el paquete `dplyr` para combinar la lista de tablas en el dataframe, adicionalmente, se aplica una primera limpieza de los datos con el condicional `if` para eliminar la columna innecesaria de índice.

```{r}
# Lista tablas
todas_las_tablas <- list()

# Iterar en las 10 paginas
for (i in 1:10) {
  url_tabla <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_", i, ".html")
  
  pagina_tabla <- read_html(url_tabla)
  
  # Extraer tabla
  tabla <- pagina_tabla %>% html_element("table") %>% html_table()
  
  # Agregar la tabla a la lista
  todas_las_tablas[[i]] <- tabla
}

# Unir todas las tablas en un solo dataframe
df_GEIH <- bind_rows(todas_las_tablas)

```

```{r}
# Eliminar columna de indice 

if ("...1" %in% colnames(df_GEIH)) {
  df_GEIH <- df_GEIH %>% select(-`...1`)
}
```

#### Proceso de limpieza de los datos

En primer lugar, se filtraron las personas ocupadas mayores de 18 años utilizando las variables "ocu" y "age". El término de personas ocupadas hace referencia a aquellos individuos que están trabajando en alguna actividad económica, ya sea de manera formal o informal, y que se encuentran dentro de la edad laboral. Para este análisis, se consideró que la edad legal para trabajar en Colombia es de 18 años, a partir de la cual no se aplican las restricciones que rigen para los menores de edad.

Lo anterior fue el resultado de la exploración de los datos, en la que se identificaron variables similares, como "ocu" y "dsi". Ambas son variables dicotómicas: "dsi" toma el valor de 1 si la persona está desempleada y 0 en caso contrario, mientras que "ocu" toma el valor de 1 si la persona está ocupada y 0 si no lo está. Dado que nuestro análisis se enfoca en las personas que están trabajando, se eligió la variable "ocu", ya que permite estudiar específicamente a las personas ocupadas. De este filtro, se da como resultado una base de datos con 16.542 observaciones con 177 variables.

```{r}
# Resumen de la Base de datos df_GEIH
skim(df_GEIH) %>% head()

df_GEIH %>%
  select(age, ocu) %>%  # Visualizar solo las columnas clave
  sample_n(10)  # Mostrar 10 filas aleatorias

# Verificar estructura de las variables clave
str(df_GEIH[, c("age", "ocu")])

# Filtrar personas mayores de 18 años que están empleadas
df_filtrado <- df_GEIH %>%
  filter(age >= 18, ocu == 1) 

head(df_filtrado)
```

#### Elección de variables

Se construye un nuevo dataframe a partir de la Gran Encuesta Integrada de Hogares (GEIH), seleccionando las variables relevantes para el presente análisis. El objetivo es modelar y explicar el salario por hora de una persona en función de diversas características individuales y laborales.

A continuación, se describen las variables elegidas y su pertinencia en la estimación del modelo, justificando su inclusión con base en la teoría económica y la literatura empírica sobre determinantes salariales.

-   **Y_total_m_ha (Ingreso total mensual):** Esta variable es la dependiente y capta el salario por horal del total mensual que recibe un trabajador, que es directamente el objeto de análisis en estudios de salarios.

-   **Age (Edad):** La edad influye en los salarios, ya que está vinculada a la experiencia laboral y las habilidades adquiridas a lo largo del tiempo. En general, la relación entre edad y salario es positiva hasta cierto punto, ya que la experiencia suele traducirse en mayores ingresos. Sin embargo, en etapas más avanzadas, esta relación puede estabilizarse o incluso disminuir. Según X, los jóvenes enfrentan tasas de desempleo más altas en el mercado laboral, mientras que las personas de mayor edad suelen experimentar períodos de desempleo más cortos, pero con una duración más prolongada. Orlando, A. (2000). DNP.

-   **Sex (Género):** Esta variable es una dummy que toma el valor de 1 si la persona es mujer y 0 si es hombre. Su relevancia radica en el análisis de las diferencias salariales entre géneros. En numerosos estudios económicos, se ha observado la existencia de una brecha salarial de género, donde, en promedio, las mujeres ganan menos que los hombres por realizar el mismo trabajo o tareas similares. La teoría de discriminación laboral de Joan Robinson (1933) sostiene que, aunque hombres y mujeres sean igualmente productivos, las mujeres recibirán un salario inferior debido a que la curva de oferta laboral femenina es menos elástica que la masculina. (Cuervo Alvarado, M., 2022).

-   **MaxEducLevel (Máximo nivel educativo):** El nivel educativo es una variable clave que afecta el salario. Los individuos con mayor nivel educativo suelen tener acceso a trabajos mejor remunerados debido a que se asocia con mayor capital humano, habilidades y capacidades técnicas como lo define la teoría planteada por Becker (1964).

-   **P6426 (Tiempo en la empresa):** Esta variable se refiere al número de años que una persona ha trabajado en la misma organización. Puede estar relacionada con el aumento salarial por antigüedad. Según Gary Becker y Robert E. Lucas Jr., el capital humano abarca las habilidades y cualidades que hacen a las personas más productivas, siendo así un motor clave para el desarrollo organizacional. Este capital se convierte en una ventaja fundamental para las empresas, permitiéndoles desempeñarse eficazmente en su entorno. (Cuervo Alvarado, M., 2022).

-   **P6870 (Tamaño de la empresa):** El tamaño de la empresa es una variable clave en la determinación salarial. Según Cuervo Alvarado (2022), las pequeñas empresas, que emplean de 1 a 10 personas, son determinantes en el tamaño y la producción de la industria. Sin embargo, en general, las empresas más grandes tienen una mayor capacidad económica, lo que les permite ofrecer salarios más altos y proporcionar mejores compensaciones a sus empleados.

-   **Depto (Departamento):** El departamento donde vive un empleado puede influir en el salario. Diferentes departamentos tienen diferentes niveles de remuneración, dependiendo de la especialización, la demanda de las habilidades y el tipo de trabajo realizado.

-   **Formal (Formalidad del empleo):** Según Orlando (2000), en su informe del DNP, la formalidad del empleo se refiere a si el trabajador está registrado formalmente o si trabaja en la informalidad. Los trabajos formales suelen tener mejores salarios, beneficios y seguridad social, mientras que los trabajos informales presentan salarios más bajos y menor estabilidad.

-   **P6100 (Seguridad social):** La Organización Internacional del Trabajo hace referencia al régimen al que un trabajador está afiliado dentro del sistema de salud. El acceso a la seguridad social, especialmente a través de los diferentes regímenes (contributivo, especial y subsidiado), está estrechamente vinculado con la estabilidad económica y las oportunidades de ingresos.

```{r}
# Nuevo data frame
df_salario <- df_filtrado %>%
  select(y_total_m_ha, age, ocu, sex, maxEducLevel, p6426, p6870, depto, formal, p6100)

# Cambio del nombre de algunas variables
df_salario <-  df_salario %>% 
  rename(salario_hora = y_total_m_ha,
         max_nivel_educ = maxEducLevel,
         tiempo_empresa = p6426,
         tamaño_empresa = p6870,
         segu_social = p6100
         )


# Estadísticas de df_salario
skim(df_salario)
str(df_salario)
  
```

Así mismo, para poder trabjar con los datos de forma adecuda, es necesario realizar un análisis descirptivo de las variables seleccionadas como se muestra a continuación:

-   **Tipos de datos:**

    -   *Numeric:* como variable continua se identifica al salario_hora.

    -   *Interger:* como variables categóricas con números enteros se identifica a las variables, age, ocu, sex, max_nivel_educ, tiempo_empresa, tamaño_empresa y depto.

-   **Estadísticas descriptivas por variables:** (describir si tiene missing values, media, complete_rate, desviación estándar, cuartiles)

    -   *salario_hora:* la variable dependiente presenta 1.778 valores faltantes, lo que se traduce en un 89,25% de los valores completos. La media del salario_hora es de 8.541 COP y una desviación estándar de 13.86. El valor mínimo del salario por hora es de 0,47 COP, el primer cuartil de los datos son 3.796 COP, el sgundo cuartil o también conocido como la mediana de los datos es de 4.837 COP, el tercer cuartil es 7.899 COP y por último el máximo salario por hora es de 350.583 COP. Por último, el histograma indica una asimetría positiva debido al valor máximo.

    -   *age:* la variable no cuenta con valores faltntes, indicando el 100% de sus valores completos. La edad promedio de los individuos es de 39 años, con una desviación estándar de 13,48. La edad mínima registrada es 18 años, el primer cuartil corresponde a 28 años, la mediana a 38 años, el tercer cuatil a 50 años y el valor máximo es de 94 años. A partir del histograma, se observa un concentración promedio en edades menores al segundo y tercer cuaril.

    -   *ocu:* la variable no presenta valores faltantes y tiene completos el 100% de los datos. Dado que es una variable dicotómica, no se considera relevante explicar otras estadísticas.

    -   *sex:* la variable no presenta valores faltantes y tiene completos el 100% de los datos. Dado que es una variable dicotómica, no se considera relevante explicar otras estadísticas. Sin embargo, toma el valor de 1 cuando la persona es mujer y 0 cuando es hombre.

    -   *max_nivel_educ:* la variable categorica para el nivel educativo presenta 1 valor faltante, por lo tanto, tiene un 99,99% de los datos completos. Ahora para comprender el análisis de las estadísticas es necesario conocer las respectivas categorías del máximo nivel educativo alcanzado o el último grado aprovado:

        -   1 = "Ninguno"

        -   2 = "Preescolar"

        -   3 = "Básica primaria" (1ro - 5to)

        -   4 = "Básica secundaria" (6to - 9no)

        -   5 = "Media" (10mo - 13mo)

        -   6 = "Superior o universitaria"

        -   7 = "No sabe, no informa"

        .Analizando el histograma, se puede concluir que la mayor frecuencia de respuesta de las personas respecto a su nivele educativo es "No sabe, no informa".

    -   *tiempo_empresa:* no tiene valores faltanes y tiene un 100% de los datos completos. El tiempo de trabajo en la empresa se encuentra medido en meses, donde el promedio es de 63,76 meses (5,3 años) con una desviación estándar de 89,48. El valor mínimo (primer cuartil) es de 0 meses, indicando probablemente que las personas en el momento de la encuesta habían iniciado a trabajar y no habían cumplido un mes en la empresa. La mediana es 24 meses (2 años) y el tercer cuatil corresponde a 84 meses (7 años). Finalmente, el máximo tiempo registrado del tiempo de trabajo en la empresa es de 720 meses (60 años), es importante resaltar que de acuerdo a las normativas laborales colombianas, una persona con trabajo formal puede llegar a trabajar en promedio entre 35 a 40 años, sin emabrgo, es posible que esto no aplique para personas con trabajos informales. Por último, se observa que el histograma tiene una cola a la derecha, indicando que la gran parte de la muestra se encuentra distribuida entre el primer y segundo cuartil.

    -   *tamaño_empresa:* no tiene valores faltanes y tiene un 100% de los datos completos. Ahora para comprender el análisis de las estadísticas es necesario conocer las respectivas categorías del tamaño de la empresa:

        -   1 = "Trabaja solo"
        -   2 = "2 a 3 personas"
        -   3 = " 4 a 5 personas"
        -   4 = "6 a 10 personas"
        -   5 = "11 a 19 personas"
        -   6 = "20 a 30 personas"
        -   7 = "31 a 50 personas"
        -   8 = "51 a 100 personas"
        -   9 = "101 o más personas"

        De acuerdo al histograma, la distribución de la muestra sugiere que la mayoría de las personas trabajan en empresas de la categoría 9.

    -   *depto:* no tiene valores faltanes y tiene un 100% de los datos completos. Esta variable contiene el código del departamento (11), el cuál se ha identificado como único valor en df_salario, haciendo referencia que todas las observaciones del data frame son personas que viven en Bogotá.

    -   *formal:* no tiene valores faltanes y tiene un 100% de los datos completos. Dado que es una variable dicotómica, no se considera relevante explicar otras estadísticas. Sin embargo, toma el valor de 1 cuando la persona tiene un trabajo formal y 0 cuando la persona tiene un trabajo informal.

    -   *segu_social:* la variable tiene 1.403 valores faltante, es decir que cuenta con un 91,51% de datos completos, como es una variable categórica, es necesario conocer las mismas para comprender el análisis de las estadísticas:

        -   1 = "Regimen contributivio"
        -   2 = "Regimen especial"
        -   3 = "Regimen subsidiado"
        -   9 = "No sabe, no informa"

        A partir del histograma, la distribución de la muestra de acuerdo a las categorías se centra principalmente en la categoría 1, sin embargo, también se debe considerar a la categría 2.

#### Valores faltantes

Se procedió a identificar los datos faltantes. Para algunas variables, se utilizó el promedio de los valores disponibles, lo que resultó en una nueva base de datos denominada “df_salario” con 16,542 observaciones y 10 variables. Posteriormente, se calcularon los porcentajes de valores faltantes por cada variable y se graficó la distribución de estos porcentajes.

En cuanto a la imputación de los valores faltantes, se abordó de acuerdo con el tipo de variable. Para las variables categóricas, como educación y seguridad social, se ordenaron de manera descendente y se calculó el valor más común en cada categoría, que fue utilizado para reemplazar los datos faltantes.

Para la imputación de la variable continua, salario por hora, se analizó su distribución mediante un gráfico, observándose que presenta una cola hacia la derecha. Debido a esta distribución, se optó por imputar los valores faltantes con la mediana, ya que representa mejor el valor central de los datos. Finalmente, se verificó que no quedaran valores faltantes en la base de datos.

Con el resumen de estadísticas del nuevo data frame creado, se identifica la cantidad de valores faltantes (n_missing) en las variables salario_hora, segu_social y max_nivel_educ. A continuación, se procede a validar la información e imputar los valores faltantes de acuerdo a las caracterísitcas de las variables para poder estimar los modelos más adelante.

```{r}
# datos faltantes con skim
base_faltantes <- skim(df_salario) %>% select( skim_variable, n_missing)

# calcular el porcentaje de valores faltantes
obs <- nrow(df_salario) 

base_faltantes<- base_faltantes %>% mutate(p_missing = n_missing/obs)
base_faltantes

# ordenar de forma descendente
base_faltantes <- base_faltantes %>% arrange(-n_missing)

# mantener solo las variables con valores faltantes
base_faltantes<- base_faltantes %>% filter(n_missing!= 0)
base_faltantes

# gráfica de los valores faltantes
ggplot(base_faltantes, aes(x = reorder(skim_variable, -n_missing), y = p_missing, fill = skim_variable)) +
  geom_bar(stat = "identity", color = "black", fill = "gray70", width = 0.5) +  
  scale_y_continuous(labels = scales::percent) +  
  labs(title = "GRÁFICO 1 - PORCENTAJE DE VALORES FALTANTES POR VARIABLES", 
       x = "Variables",
       y = "Porcentaje de valores faltantes") + 
  theme_classic() +  # **Formato más limpio y académico**
  theme(plot.title = element_text(size = 12, hjust = 0.5),  
        axis.title = element_text(size = 10),  
        axis.text = element_text(size = 10)) +  
  coord_flip()  

# Guardar 
ggsave("valoresfaltantes1.png", dpi = 300)

# Imputación de valores faltantes con el Método 1: Media/Mediana

## Imputación de variables categóricas: max_nievl_educ y segu_social

### Calcular los valores mas comunes
educacion <- as.numeric(names(sort(table(df_salario$max_nivel_educ), decreasing = TRUE)[1]))

seg_soc <- as.numeric(names(sort(table(df_salario$segu_social), decreasing = TRUE)[1]))

### Imputación de los valores faltantes para ambas variables
df_salario <- df_salario  %>%
  mutate(max_nivel_educ = ifelse(is.na(max_nivel_educ) == TRUE, educacion , max_nivel_educ)) %>% 
  mutate(segu_social = ifelse(is.na(segu_social) == TRUE, seg_soc , segu_social))

## Imputación de variable continua: salario por hora

## Gráfica de la distribución del salario por hora
ggplot(df_salario, aes(x = salario_hora)) +
  geom_histogram(color = "black", fill = "gray70", bins = 50) + 
  geom_vline(xintercept = median(df_salario$salario_hora, na.rm = TRUE), 
             linetype = "dashed", color = "black", linewidth = 1) +  # mediana
  geom_vline(xintercept = mean(df_salario$salario_hora, na.rm = TRUE), 
             linetype = "dotted", color = "blue", linewidth = 1) +  # media
  scale_x_continuous(labels = comma) +  
  ggtitle("GRÁFICO 2-INGRESO TOTAL POR HORA") +  
  labs(x = "Salario por hora", 
       y = "Frecuencia") +
  theme_classic() +
  theme(plot.title = element_text(size = 12, hjust = 0.5),  
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 10))

# Guardar AER
ggsave("salariohora2.png", dpi = 300)
#### Debido a que la distribución del ingreso total por hora tiene un cola a la derecha, se deicide utilizar la mediana para imputar los valores faltantes.

### Imputación de valores faltantes para variable continua
df_salario <- df_salario %>% 
  mutate(salario_hora = ifelse(is.na(salario_hora) == TRUE, median(df_salario$salario_hora, na.rm = TRUE) , salario_hora))

# Validación de la correcta imputación de valroes faltantes en el data frame de salario
sum(is.na(df_salario))
```

## 3. Perfil de edad-salario

Una gran cantidad de evidencia en economía laboral sugiere que el perfil de edad-salario del trabajador típico tiene una trayectoria predecible: “Los salarios tienden a ser bajos cuando el trabajador es joven; aumentan a medida que el trabajador envejece, alcanzando un máximo alrededor de los 50 años; y la tasa salarial tiende a permanecer estable o a disminuir ligeramente después de los 50 años”. En esta subsección vamos a estimar el perfil de edad-salario para los individuos de esta muestra:

En economia es usual formular modelos con variables que tengan una condicion cuadratica, este tipo de modelos lo que buscan es captar los efectos marginales decrecientes o crecientes en la funcion. En este sentido, el modelo de estimación planteado esta en funcion de una sola variables $$Age$$.

$$
log(w) = β_0 + β_1Age + β_2Age^2 + u \quad (1)
$$

Ademas, es importante recordar que el estimador $$β_1$$ no mide la variacion en $$Log (w)$$, porque, al realizar un analisis ceteris paribus sobre la variable $$Age^2$$, la variable $$age$$ será constante. Por lo tanto, la ecuación estimada, es:

$$
log(\hat{w}) = \hat{β_0} +\hat{β_1}Age +\hat{β_2}Age^2 + u \quad (2)
$$

De la estimación anterior, se tiene una aproximación luego de derivar la varible $$Log (w)$$ entre la variable $$Age$$, así

$$ 
\frac{\Delta \log(\hat{w})}{\Delta \textit{Age}} =\hat{β_1} + 2\hat{β_2}Age + u \quad (3)
$$

Ahora, se puede mencionar que, la relación $$Log (w)$$ y $$\Delta Age$$ depende de la variable $$Age$$. Entonces, si se reemplaza el valor de 0 en la variable $$Age$$, se puede interpretar el coeficiente $$β_1$$ como el cambio marginal aproximado de pasar de 0 a 1. A continuación, estimaremos los coeficientes de la siguiente ecuación,

```{r}
#Estimacion de regresion log (salario)
modelo_age_wage <- lm(log(salario_hora) ~ age + I(age^2), data = df_salario) 

#Tabla modelo1
stargazer(modelo_age_wage, 
          type = "text",            
          title = "TABLA 1-MODELO DE SALARIO",
          covariate.labels = c("Edad", "Edad al Cuadrado"), 
          dep.var.labels = "Log(Salario por Hora)",  
          digits = 3,                
          align = TRUE,           
          star.cutoffs = c(0.1, 0.05, 0.01)) 


```

# Interpretación de los resultados de la regresión log (salario)

El resultado de la estimación indica que el coeficiente $$Age$$ es positivo y $$Age^2$$ es negativo, esto predetermina que, valores pequeños en $$Age$$ tiene un efecto positivo en $$log(w)$$, por el contrario valores grandes en $$Age$$ genera una condicion de decrecimiento sobre el $$log(w)$$. De esta manera, tomaremos los multiplos de 18 años para realizar el analisis del cambio $$\Delta log(\hat{w})$$. Veamos, cuando la variable $$Age$$ es igual a 18 años, $$\Delta log(\hat{w})$$ es igual a 2,66% Ahora, cambiamos el valor a 36 años, $$$\Delta log(\hat{w})$$ es igual a 0,69% por último, $$Age$$ sera 54 años y por lo tanto $$\Delta log(\hat{w})$$ es igual a -1,29%.

```{r}
# Gráfico del perfil estimado de ingresos y edad

edades <- unique(df_salario$age)  

# Calcular los log salarios predichos por edad
log_salarios_predichos <- coef(modelo_age_wage)["(Intercept)"] +
                          coef(modelo_age_wage)["age"] * edades +
                          coef(modelo_age_wage)["I(age^2)"] * edades^2

# Obtener intervalos de confianza
nueva_data <- data.frame(age = edades)
predicciones <- predict(modelo_age_wage, newdata = nueva_data, 
                       interval = "confidence", level = 0.95)
lower_ci_log <- predicciones[, "lwr"]
upper_ci_log <- predicciones[, "upr"]


# Data frame con salario log y reales
df_pred <- data.frame(
  edad = edades,
  log_salario = log_salarios_predichos,
  salario = exp(log_salarios_predichos),
  lower_ci = exp(lower_ci_log),
  upper_ci = exp(upper_ci_log)
)

# Crear datos para la leyenda
df_pred$tipo <- "Salario estimado"
df_puntos <- df_pred %>% filter(edad %% 10 == 0)
df_puntos$tipo <- "Valores cada 10 años"

# Grafico del perfil estimado de ingresos y edad
ggplot(df_pred, aes(x = edad, y = salario)) +

  geom_ribbon(data = df_pred, 
              aes(x = edad, ymin = lower_ci, ymax = upper_ci, fill = "Intervalo de confianza 95%"),
              alpha = 0.2) +
  geom_line(data = df_pred, 
            aes(x = edad, y = salario, color = "Salario estimado"),
            size = 1) +
  geom_point(data = df_puntos,
             aes(x = edad, y = salario, shape = "Valores cada 10 años"),
             color = "blue", size = 2) +
  
  # Identificación colores y formas  leyenda
  scale_fill_manual(values = c("Intervalo de confianza 95%" = "red")) +
  scale_color_manual(values = c("Salario estimado" = "black")) +
  scale_shape_manual(values = c("Valores cada 10 años" = 16)) +
  
  #Titulo de la grafica
  labs(title = "GRÁFICO 3-PERFIL ESTIMADO DE INGRESOS POR HORA SEGÚN LA EDAD",
       x = "Edad",
       y = "Salario Promedio Estimado")+
  
  # Convenciones de la grafica
  guides(fill = guide_legend(override.aes = list(alpha = 0.5)),
         color = guide_legend(),
         shape = guide_legend()) +
  
  # Estilo de las convenciones
  theme_classic() +  
  theme(
    plot.title = element_text(size = 12, hjust = 0.5, face = "plain"),
    axis.title = element_text(size = 10),  
    axis.text = element_text(size = 10),
    legend.position = "bottom",
    legend.title = element_blank(),
    legend.box = "horizontal"
  )

# Guardar
ggsave("perfilingresosedad3.png", dpi = 300)

```

Con el analisis anterior, podemos observar el comportamiento de la ecuación estimada es parabolico, es decir, en la "edad pico" se encuentra el punto de inflexión. Todas las edades menores a la "edad pico", la variable $$log(\hat{w})$$ será cerciente y para edades mayores a la "edad pico" la varible $$log(\hat{w})$$ seran decreciente. Asi las cosas, es necesario conocer como se calcula el punto de inflexión.

$$
\frac{\Delta \log(\hat{w})}{\Delta \text{Age}} = 0  \quad (4)
$$

$$
\frac{\Delta \log(\hat{w})}{\Delta \text{Age}} = \hat{\beta}_1 + 2\hat{\beta}_2 \cdot \text{Age}  \quad (5)
$$

$$
0=\hat{β_1}+2\hat{β_2}Age    \quad (6)
$$

$$
\text{Age}_{\text{pico}} = -\frac{\hat{\beta}_1}{2\hat{\beta}_2} \quad (7)
$$

```{r}
# Obtener los coeficientes de la regresion log(w) = β0 + β1Age + β2Age2 + u
coefs <- modelo_age_wage$coef
coefs

```

```{r}
#Extraer los coeficientes de la regresión

b0 <- coefs [1] #Intercepto
b1 <- coefs [2] #age
b2 <- coefs [3] #age^2

```

```{r}
#Obtener la edad pico del problema segun los betas obtindos

peak_age <- -b1/(2*b2)
peak_age

```

El punto de inflexión de la ecuacion estimada donde esta localizada la edad pico corresponde a 42.25 años.

Significancia: Según los resultados obtenidos en la regresión todos los coeficientes obtenidos son estadisticamente significativos al 0.01 (99%).

Bondad de ajuste: El R² es 0.0194 y R² ajustado da el valor de 0.01932 , esto indica que el modelo explica el salario en un 1.93%. Estos valores bajores indican que el modelo captura una parte de la relación y existen otros factores que afectan el logaritmo de salario no incluidos en el modelo.

# Análisis de la “edad pico” con sus respectivos intervalos de confianza.

Luego de estimar, predecir y analizar las ecuaciones y gráficas podemos sugerir que el comportamiento del salario en funcion de la edad en la población encuestada sugiere que los salarios son bajos a la edad de 18 años. Además, se noto que el salario mejora con el aumento de los años. No obstante, el ritmo de crecimiento del salario es más grande en comparación con edades medias, como por ejemplo, los 36 años, donde se registro un cambio de 0,69%. De otro lado, se registro la edad pico para este estudio en 42.25 años de edad, este punto es importante por dos razones. La primera, es el punto de inflexión entre el cambio positivo y el cambio negativo  en el ingreso. la segunda, que en promedio se referencia la edad pico a los 50 años, esto puede sugerir que podemos tener otras variables que no fueron incluidas en el estudio/ecuación que generen una disminución de la edad y obtener mejores salarios. 


```{r}
# Función que obtiene los coefficientes de modelo

peak_age_fn <- function(data ,index) {
  
          coef_boot <- lm(log(salario_hora) ~ age + I(age^2), 
                          data = df_salario, 
                          subset = index)
          
          coef_boot_b0 <- coef_boot$coefficients [1]
          coef_boot_b1 <- coef_boot$coefficients [2]
          coef_boot_b2 <- coef_boot$coefficients [3]
          
          peak_age_boot <- -coef_boot_b1/(2*coef_boot_b2)
          
          return(peak_age_boot)
               }

# Validación de la edad pico desde la fila 1 hasta la fila 16542 
peak_age_fn(df_salario, 1:nrow(df_salario))

length(df_salario$age)

#Estimar la edad pico, sesgo y desviacion estandar por medio de Bootstrap

set.seed(123)

#LLamado de la función boot

peak_age_boot <- boot(df_salario, peak_age_fn,R=1000)
peak_age_boot

#Crear un data frame que almacene los resultado de peak_age_boot

peak_age_boot_df <- data.frame(peak_age = peak_age_boot$t)
summary(peak_age_boot_df)

#Calcular los cuantiles de confianza del peak_age_boot
quan_peak_age_boot <- quantile(peak_age_boot_df$peak_age, probs = c(0.025,0.975))
quan_peak_age_boot

#Graficar el histograma

p <- ggplot(peak_age_boot_df, aes(x = peak_age)) +
  geom_histogram(fill = "gray70", color = "black", bins = 30) +
  geom_vline(xintercept = quan_peak_age_boot, col = "black", linetype = "dashed", linewidth = 1) +  
  labs(title = "GRÁFICO 4-DISTRIBUCIÓN DE MUESTRA", 
       x = "Edad", 
       y = "Frecuencia") +
  theme_classic() +  # Fondo blanco, sin cuadrícula
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),  
    axis.title.x = element_text(size = 10),  
    axis.title.y = element_text(size = 10)
  )

p
# Guardar con alta resolución (AER recomienda 300 DPI)
ggsave("histogramadistribucionmuestra4.png", plot = p, dpi = 300, width = 8, height = 6)


```


En conclusion, es de notar que esta variable no es la unica que determina el valor, podriamos incluir, por ejemplo, la industria, la experiencia de laboral, la cantidad de años de estudio, ranking institucion educativa, etc. y otras que habilidades sociales que pueden ser dificiles de cuantificar en cuyo casos podria ayudar a explicar el comportamiento del salario en funcion de la edad. 

## 4.La brecha salarial de género.

Los responsables de las políticas se han preocupado durante mucho tiempo por la brecha salarial de género.

$$
<<<<<<< HEAD
log(w) = β_1 + β_2Female + u \quad (8)
$$ 
donde Female es un indicador que toma uno si el individuo en la muestra se identifica como mujer.
$$
log(w) = β1 + β2Female + u \quad (8)
$$ 
donde Female es un indicador que toma uno si el individuo en la muestra se identifica como mujer.

```{r}
#Se crea la variable female en nuestra base

df_salario <- df_salario %>%
              mutate(female = ifelse(sex == 0, 1, 0))

#Estimación de regresion log (salario) con female
reg_female <- lm(formula = log(salario_hora) ~ female, data =df_salario)

stargazer(reg_female, 
          type = "text",            
          title = "TABLA 3-MODELO DE SALARIO SEGÚN GÉNERO", 
          dep.var.labels = "Log(Salario por Hora)",  
          digits = 3,                
          align = TRUE,           
          star.cutoffs = c(0.1, 0.05, 0.01))

```

\*Interpretación - Significancia global: El modelo es significativo al 0,01 (99%), es decir, la variable del modelo explica el salario por hora.

-   Bondad de ajuste: El R² es 0.002 y R² ajustado da el valor de 0.002 , esto indica que el modelo explica el salario en un 0.2%

-   El error estandar para este modelo es de0.787 y esto indica la dispersión entre las 16542 observaciones y la estimación.

-   Significancia parcial: La variable female es significativa al 0.01 (99%), el error estandar es de 0.012 y explica que si es mujer, en promedio el salario disminuye en 7.9%

## 4.1 Salario igual para trabajos iguales?

El eslogan "salario igual por trabajo igual" es una forma de interpretar que los empleados con características laborales similares, no debe existir ninguna brecha salarial de genero. En esta sección, se utilizará el modelo Frisch-Waugh-Lovell (FWL) para estimar la brecha salarial condicional, incorporando variables de control que reflejan las características semejantes de los trabajadores y los puestos de trabajo. El procedimiento se divide en tres pasos, que se describen a continuación:

Paso 1: Estimación de la regresión con todos los predictores completos, y cálculo de los residuos u. Paso 2: Se realiza una regresión auxiliar utilizando los residuos obtenidos en el paso anterior. Paso 3: El Teorema de Frisch-Waugh-Lovell establece que los residuos de la primera y segunda regresión son numéricamente equivalentes.

```{r}
# PASO 1
# Estimación de regresion log (salario) con female y otros controles
reg_female_controles <- lm(formula = log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                          data =df_salario)

# PASO 2
# Regresión auxiliar para obtener los residuos u
reg_female_residuos <- lm(formula = female  ~ max_nivel_educ + tiempo_empresa + age, 
                          data =df_salario)

residuos_female <- residuals(reg_female_residuos)

# PASO 3
#Correr la primera regresión con los residuos de female 
reg_residuos_female <- lm(log(salario_hora) ~ residuos_female, data = df_salario)


stargazer(reg_female_controles, reg_residuos_female, 
          type = "text", 
          title = "TABLA 4-ESTIMACIÓN DE GÉNERO EN SALARIO",
          column.labels = c("Modelo Condicional", "Modelo Incondicional"), 
          covariate.labels = c("Mujer", "Nivel Educativo", "Tiempo en Empresa", "Edad", "Residuos de Mujer"),
          dep.var.labels = "Log(Salario por Hora)",  
          digits = 3,                
          align = TRUE,           
          star.cutoffs = c(0.1, 0.05, 0.01),
          notes = c("Significancia: * p<0.1, ** p<0.05, *** p<0.01"))
```

Análisis del modelo condicional e incondicional:

El coeficiente de la variable "female" en ambos modelos sugiere que, en promedio, las mujeres ganan un 10.7% menos que los hombres en salario por hora, incluso después de controlar por variables como el nivel educativo, la antigüedad en la empresa y la edad. Ambas variables son estadísticamente significativas, y se observa que el error estándar del coeficiente en el modelo condicional es 0.011, mientras que en el modelo incondicional es ligeramente más alto, 0.012.

El R² de ambos modelos es relativamente bajo, lo cual indica que estos modelos no tienen un buen ajuste con la muestra. Generalmente, se espera que el R² se acerque al 40%-80% para considerar los modelos más explicativo, pero en este caso ambos valores son menores (0.192) y (0.005), lo que sugiere que las variables elegidas no explican del todo las diferencias salariales.

El estadístico F en ambos modelos es significativo, lo que indica que al menos una de las variables es relevante para predecir el salario por hora. Sin embargo, el modelo condicional tiene un ajuste superior, ya que controla por variables clave que influyen en los salarios, lo que lo convierte en un modelo más robusto y confiable en comparación con el modelo incondicional.

De los resultados de las regresiones se puede observar que el teorema FWL se cumple porque los coeficientes de los betas son iguales.

```{r}
#Se comparan los coeficientes de female

beta_female_controles <- coef(reg_female_controles)["female"]
beta_femal_residuos <- coef(reg_residuos_female)["residuos_female"]

beta_female_controles 
beta_femal_residuos
```

Posteriomente, se estima el modelo FWL con Boostrap

```{r}
# Función para sacar residuales
fwl_boot <- function(data ,index) {
  
          coef(lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                          data = df_salario, 
                          subset = index))[2]
               }

# Validación
fwl_boot(df_salario, 1:nrow(df_salario))
  
# Semilla para hacerlo reproducible
set.seed(123)

# Estimaciones y errores estandar
errorestandar_boot <-  boot(df_salario, fwl_boot, R = 1000)
errorestandar_boot

```

Análisis de comparación de las estimaciones y los errores estándar

Al comparar las estimaciones de los coeficientes para female en los dos modelos (uno con controles y otro con los residuos de female), se observa que las estimaciones son prácticamente iguales cuando se utiliza el bootstrap. Sin embargo, los errores estándar son ligeramente diferentes entre los métodos con FWL y FWL con Boostrap. En el modelo estimado mediante el método FWL, el error estándar para female es de 0.011, mientras que en el modelo ajustado por los residuos de female, el error estándar aumenta ligeramente a 0.012. Aunque ambos valores son bastante similares, el modelo con los residuos refleja un pequeño aumento en la variabilidad de la estimación.

El valor del error estándar de la estimación de female mediante el método FWL con bootstrap es 0.01096617, lo que es consistente con los resultados obtenidos en el modelo con controles. Además, se observa que la variabilidad en la estimación de female es más baja en el modelo con bootstrap, en comparación con el modelo FWL ajustado por los residuos, lo que sugiere una mayor precisión en las estimaciones obtenidas mediante el bootstrap.

A pesar de estos pequeños cambios en los errores estándar, la brecha salarial de género sigue siendo evidente. El coeficiente negativo para female en ambos modelos indica que las mujeres ganan, en promedio, menos que los hombres, lo que confirma la persistencia de la brecha salarial.

Ahora, se graficará el perfil de edad- salario previsto y se calculará las edades pico implícitas con los respectivos intervalos de confianza por género

```{r}
ggplot(df_salario) + 
  geom_point(
    aes(x = age, y = log(salario_hora)),
    color = "gray30", size = 1.5, alpha = 0.6
  ) + 
  labs(
    title = "GRÁFICO 4-RELACIÓN ENTRE EDAD Y SALARIO POR HORA",
    x = "Edad",
    y = "Log(Salario por Hora)"
  ) +
  theme_classic() + 
  theme(
    plot.title = element_text(hjust = 0.5, size = 12),
    axis.title = element_text(size = 10),  
    axis.text = element_text(size = 10)  
  )

# Guardar
ggsave("edadsalario4.png", dpi = 300)
```

Discusión de edades pico a partir del gráfico (...)

Para concluir este análisis, retomamos lo que señala Sabogal (2012), quien destaca que en Colombia, las mujeres perciben salarios más bajos que los hombres, a pesar del aumento en su participación laboral, el mayor número de horas trabajadas y ciertas características observables, como el nivel educativo, durante las últimas tres décadas.

A partir de los resultados obtenidos en los modelos condicional e incondicional de la brecha salarial, se puede inferir que las variables contribuyen a un problema mixto que involucra tanto la selección como la discriminación salarial hacia las mujeres.

La selección no solo puede depender de características observables tales como la edad, la educación y la experiencia, sino también verse influida por factores históricos o estructurales de discriminación. Por ejemplo, si las mujeres son seleccionadas para desempeñar roles en ocupaciones de menor remuneración debido a estereotipos de género preestablecidos, esto puede ampliar la brecha salarial. En caso de que la brecha condicional persista, aún después de ajustar por variables observables, podríamos estar ante una combinación de discriminación estructural y diferencias ocupacionales no completamente reflejadas en el modelo.

## 5. Predicción del salario

En las secciones anteriores, se estimó algunas especificaciones teniendo en cuenta la inferencia. En esta sección, evaluaremos el poder predictivo de estas especificaciones.

### 5.1. División de la muestra

```{r}
# Semilla para consistencia de resultados
set.seed(10101) 

# Dividr la muestra en entrenamiento y prueba
sample_salario <- sample(c(TRUE, FALSE), nrow(df_salario), replace=TRUE, prob=c(0.7,0.3))

# Validación de la division de la muestra
sum(sample_salario)/nrow(df_salario)

# División en datos de training (70%) y test (30%)
train_sample  <- df_salario[sample_salario, ] 
test_sample   <- df_salario[!sample_salario, ]
```

El siguiente gráfico muestra como se distribuyen las observaciones entre el conjunto de entrenamiento y el de prueba

```{r}
# Crear el conjunto de datos para la gráfica
split_data <- data.frame(
  Split = c("Train", "Test"),
  Count = c(sum(sample_salario), sum(!sample_salario)),
  Percentage = c(sum(sample_salario)/length(sample_salario) * 100, sum(!sample_salario)/length(sample_salario) * 100)
)

# Crear el gráfico
ggplot(split_data, aes(x = Split, y = Count, fill = Split)) + 
  geom_bar(stat = "identity", width = 0.5, color = "black") + 
  geom_text(aes(label = paste0(round(Percentage, 1), "%\n(n=", Count, ")")),
            vjust = 1.5, color = "black", size = 5) + 
  labs(title = "GRÁFICO 6-DISTRIBUCIÓN DE LA DIVISIÓN DE LA MUESTRA",
       y = "Número de observaciones",
       x = "") + 
  theme_classic() + 
  scale_fill_manual(values = c("gray70", "gray85")) + 
  theme(plot.title = element_text(hjust = 0.5, size = 12))  # Centrar el título

# Guardar 
ggsave("divisionmuestra6.png", dpi = 300)
```

### 5.2 Comparación del rendimiento predictivo en términos de RMSE

Para realizar una comparación significativa de los rendimientos predictivos de los modelos anteriores, también se proporcionaron cinco modelos adicionales que permiten identificar el mejor rendimiento incluyendo modelos no lienales y con mayor complejidad respecto a los estiamdos previamente. Asi las cosas, en total son 8 modelos:

#### Modelo 1: Regresión con Female y controles

$$
log(w) = β_0 + β_1Female + β_2educ + β_3tiempoempresa  +  β_4age + u \quad (9)
$$ 


#### Modelo 2: Regresión auxiliar (FWL - residuos de Female)

$$
log(female) = β_0 + β_1educ + β_2tiempoempresa  + β_3age + u \quad (10)
$$

#### Modelo 3: Regresión con residuos de Female

$$log(w) = β_0 + β_1residuosfemale + u \quad (11)$$

#### Modelo 4: Modelo sin controles (solo female)

$$log(w) = β_0 + β_1Female + β_2tamañoempresa  + u \quad (12)$$

#### Modelo 5: Modelo con interacciones (female x age)

$$log(w) = β_0 + β_1Female + β_2age + β_3female*tiempoempresa + β_4tiempoempresa + u \quad (13)$$

#### Modelo 6: Modelo no lineal con tamaño empresa²

$$log(w) = β_0 + β_1Female + β_2tamañoempresa + β_3tamañoempresa^2 + u \quad (14)$$

#### Modelo 7: Modelo con variables adicional e interaciones

$$log(w) = β_0 + β_1Female + β_2educ + β_3tiempoempresa + β_4age + β_5formal + β_6segusocial + β_7female*segusocial + β_8age^2 + u \quad (15)$$

#### Modelo 8:

$$log(w) = β_0 + β_1Female + β_2educ + β_3female*educ + β_4age + β_5age^2 + u \quad (16)$$

```{r}
# Definición de modelos

# Modelo 1: Regresión con Female y controles
m1 <- lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age, 
                           data = train_sample)

# Modelo 2: Regresión auxiliar (FWL - residuos de Female)
m2 <- lm(female ~ max_nivel_educ + tiempo_empresa + age, 
                          data = train_sample)

train_sample$residuos_f_m2 <- residuals(m2)

# Modelo 3: Regresión con residuos de Female
m3 <- lm(log(salario_hora) ~ residuos_f_m2, data = train_sample)

# Modelo 4: Modelo sin controles (solo female)
m4 <- lm(log(salario_hora) ~ female + tamaño_empresa, data = train_sample)

# Modelo 5: Modelo con interacciones (female x age)
m5 <- lm(log(salario_hora) ~ female + age + female:tiempo_empresa + tiempo_empresa, data = train_sample)

# Modelo 6: Modelo no lineal con tamaño empresa²
m6 <- lm(log(salario_hora) ~ female + tamaño_empresa + I(tamaño_empresa^2), data = train_sample)

# Modelo 7: Modelo con variables adicional
m7 <- lm(log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age + formal + segu_social + female:segu_social + I(age^2), 
                          data = train_sample)

# Modelo 8: 
m8 <- lm(log(salario_hora) ~ female + max_nivel_educ + female:max_nivel_educ + age + I(age^2), data = train_sample)

test_sample$residuos_f_m2 <- residuals(lm(female ~ max_nivel_educ + tiempo_empresa + age, data = test_sample))
```

Luego de definir los modelos, se procedra con las predicciones, comparacion los resultados del RMSE e identificacion del modelo con el mejor rendimiento predictivo.

```{r}
# Generar predicciones y RMSE
pred_1 <- predict(m1, test_sample)
salario_1 <- RMSE(exp(pred_1), test_sample$salario_hora)

pred_2 <- predict(m2, test_sample)
salario_2 <- RMSE(exp(pred_2), test_sample$salario_hora)

pred_3 <- predict(m3, test_sample)
salario_3 <- RMSE(exp(pred_3), test_sample$salario_hora)

pred_4 <- predict(m4, test_sample)
salario_4 <- RMSE(exp(pred_4), test_sample$salario_hora)

pred_5 <- predict(m5, test_sample)
salario_5 <- RMSE(exp(pred_5), test_sample$salario_hora)

pred_6 <- predict(m6, test_sample)
salario_6 <- RMSE(exp(pred_6), test_sample$salario_hora)

pred_7 <- predict(m7, test_sample)
salario_7 <- RMSE(exp(pred_7), test_sample$salario_hora)

pred_8<- predict(m8, test_sample)
salario_8 <- RMSE(exp(pred_8), test_sample$salario_hora)

# Crear la tabla con los MSE
mse_table <- data.frame(
  Modelo = c("m1", "m2", "m3", "m4", "m5", "m6", "m7", "m8"),
  MSE = c(salario_1, salario_2, salario_3, salario_4, salario_5, salario_6, salario_7, salario_8)
)

# Imprimir la tabla para comparar los RMSE
stargazer(mse_table, type = "text", summary = FALSE, title = "TABLA 5-COMPARACIÓN DE RMSE ENTRE MODELOS")
```

###5.c.i.ii. Discusión de los resultados de RMSE con Validation Set Approach

Se evaluaron ocho especificaciones diferentes usando Validation Set Approach para medir el rendimiento predictivo de los modelos con la métrica RMSE, la cual indica un mejor desempeño predictivo entre más bajo sea su nivel. El resultado hace evidente que el Modelo 7 tiene el menor valor de RMSE, con un valor de 13,448.67, por lo tanto, es el mejor en términos de RMSE. Esto sugiere que incluir controles adicionales como si la persona cuenta con seguridad social, si está en un trabajo formal, entre otros, aporta información relevante para predecir el cambio en los salarios.

El Modelo 7 tiene el mejor desempeño predictivo con un RMSE de 13,448.67. Esto es consistente con su mayor nivel de complejidad, ya que incorpora no solo los controles básicos, sino también términos adicionales como la variable formal, segu_social, la interacción female:segu_social y un término cuadrático $age^2$. El Modelo 1 sigue siendo un modelo competitivo, obteniendo el segundo mejor RMSE (13,604.31). Aunque es más simple que el Modelo 7, sigue capturando buena parte de la variabilidad del salario en función de female, max_nivel_educ, tiempo_empresa y age.

Los modelos con no linealidades e interacciones presentan mejoras en algunos casos, como el Modelo 8, que incorpora la interacción female:max_nivel_educ y logra un RMSE similar al Modelo 1 (13,644.11). El Modelo 2 es el peor en términos predictivos (RMSE = 16,113.97). Esto es esperado, ya que este modelo solo estima los residuos de female, sin utilizar directamente la variable dependiente log(salario_hora).

En términos generales, los modelos que incluyen mayores niveles de complejidad tienden a mejorar el desempeño predictivo, pero no todos los ajustes mejoran la precisión. La inclusión de interacciones y términos no lineales es útil solo si está bien justificada teóricamente.

###5.c.iii. Especificación del modelo con error de predicción: Modelo 7

```{r}
#Calculo errores de predicción
errores <- test_sample$salario_hora - exp(predict(m7, test_sample))

#Distribución de los errores
hist(errores, 
     main = "GRÁFICO 6-DISTRIBUCIÓN DE ERRORES DE PREDICCIÓN", 
     xlab = "Error de Predicción", 
     col = "gray70", 
     border = "white", 
     font.main = 1)  

#Identificar outliers en percentiles 2.5% y 97.5%
percentiles <- quantile(errores, probs = c(0.025, 0.975))
outliers <- test_sample[errores < percentiles[1] | errores > percentiles[2], ]

print(head(outliers))

#Datos más extremos y box plot outliers
par(font.main = 1)  #quitar nequilla

# Gráfico de boxplot con formato AER
boxplot(errores, 
        main = "GRÁFICO 7 - BOXPLOT DE ERRORES DE PREDICCIÓN", 
        xlab = "Errores de Predicción",  
        ylab = "Valor del Error",        
        col = "gray70",      
        border = "black",    
        outpch = 16,         
        outcol = "blue",     
        whiskcol = "black",  
        staplecol = "black",
        cex.main = 1.1,  
        cex.lab = 1.1,   
        cex.axis = 1.1)  

# Agregar líneas de percentiles (outliers)
abline(h = percentiles, col = "black", lty = 2)

```

El histograma de errores de predicción muestra una distribución sesgada a la derecha, lo que indica que la mayoría de los errores son pequeños, pero existen algunas observaciones con diferencias extremadamente grandes entre el salario real y el predicho. El boxplot confirma la presencia de valores atípicos con errores de predicción elevados. Las líneas rojas en el gráfico representan los percentiles 2.5% y 97.5%, y cualquier punto fuera de este rango es considerado un outlier. Al analizar las características de los outliers, encontramos casos llamativos, como un individuo con un salario de 44444, que es significativamente mayor que el promedio. Otros outliers presentan salarios bajos que tampoco fueron bien predichos por el modelo. Estas diferencias pueden deberse a errores en la recolección de datos, condiciones laborales particulares o factores relevantes que no fueron incluidos en la regresión.

Desde el punto de vista de la DIAN, estos valores atípicos pueden indicar posibles irregularidades. Los individuos con ingresos extremadamente altos podrían estar no declarando información, lo que podría justificar una revisión adicional. También es posible que algunos outliers sean simplemente el resultado de errores en los datos, por lo que sería necesario verificar la calidad de la información. Otra posibilidad es que el modelo no haya capturado algunas características clave del mercado laboral, lo que explicaría por qué ciertas observaciones presentan errores tan grandes.

En conclusión, la DIAN podría enfocarse en analizar más a fondo los outliers para determinar si reflejan ingresos no declarados, errores en los datos o simplemente limitaciones del modelo. Para mejorar la precisión de las predicciones, sería recomendable incluir nuevas variables que expliquen mejor los salarios atípicamente altos o bajos. También sería útil realizar un análisis más detallado sobre la naturaleza de estos empleos y sus características tributarias, para evaluar si requieren una revisión adicional.

###5.d. Calculo de error predictivo con LOOCV

Los dos modelos con menor RMSE en el paso anterior fueron el modelo 1 y el modelo 7, a continuación, se realizará el análisis correspondiente.

Modelo 1 con LOOCV

```{r}
ctrl <- trainControl(method = "LOOCV")

form_1 <- log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age

m1_loocv <- train(form_1, 
                  data = df_salario, 
                  method = 'lm', 
                  trControl = ctrl)

# Calcular RMSE en log
rmse_m1_loocv_real <- RMSE(exp(m1_loocv$pred$pred), exp(m1_loocv$pred$obs))

cat("Modelo 1 - LOOCV RMSE (Original):", round(rmse_m1_loocv_real, 2), "\n")
```

Modelo 7 con LOOCV

```{r}
ctrl <- trainControl(method = "LOOCV")

form_7 <- log(salario_hora) ~ female + max_nivel_educ + tiempo_empresa + age + formal + segu_social + female:segu_social + I(age^2)

m7_loocv <- train(form_7,
                  data = df_salario,
                  method = 'lm', 
                  trControl= ctrl)

# Calcular RMSE en log
rmse_m7_loocv_real <- RMSE(exp(m7_loocv$pred$pred), exp(m7_loocv$pred$obs))

cat("Modelo 7 - LOOCV RMSE (Original):", round(rmse_m7_loocv_real, 2), "\n")

```

Modelo 1 con Leverage LOOCV

```{r}
# Modelo 1 con LOOCV y leverage
m1_full <- lm(form_1, data = df_salario)

X_m1 <- model.matrix(m1_full)
y_m1 <- model.response(model.frame(m1_full))
beta_hat_m1 <- m1_full$coefficients
G_inv_m1 <- solve(t(X_m1) %*% X_m1)
vec_m1 <- 1 / (1 - hatvalues(m1_full))
N_m1 <- nrow(X_m1)
LOO_m1 <- numeric(N_m1)

for (i in 1:N_m1) {
  new_beta_m1 <- beta_hat_m1 - vec_m1[i] * G_inv_m1 %*% as.vector(X_m1[i, ]) * m1_full$residuals[i]
  new_error_m1 <- (y_m1[i] - (X_m1[i, ] %*% new_beta_m1))^2
  LOO_m1[i] <- new_error_m1
}

rmse_m1_loocv_laverage_real <- sqrt(mean((exp(y_m1) - exp(X_m1 %*% new_beta_m1))^2))
print(rmse_m1_loocv_laverage_real)

```

Modelo 7 con Leverage LOOCV

```{r}
# Modelo 7 con LOOCV y leverage
m7_full <- lm(form_7, data = df_salario)

X_m7 <- model.matrix(m7_full)
y_m7 <- model.response(model.frame(m7_full))
beta_hat_m7 <- m7_full$coefficients
G_inv_m7 <- solve(t(X_m7) %*% X_m7)
vec_m7 <- 1 / (1 - hatvalues(m7_full))
N_m7 <- nrow(X_m7)
LOO_m7 <- numeric(N_m7)

for (i in 1:N_m7) {
  new_beta_m7 <- beta_hat_m7 - vec_m7[i] * G_inv_m7 %*% as.vector(X_m7[i, ]) * m7_full$residuals[i]
  new_error_m7 <- (y_m7[i] - (X_m7[i, ] %*% new_beta_m7))^2
  LOO_m7[i] <- new_error_m7
}

rmse_m7_loocv_laverage_real <- sqrt(mean((exp(y_m7) - exp(X_m7 %*% new_beta_m7))^2))
print(rmse_m7_loocv_laverage_real)

```

Tabla comparativa RMSE con diferentes metolodologías

```{r}
# Tabla de comparación
comparacion_rmse <- data.frame(
  Modelo = c("M1", "M7"),
  RMSE_VSA = c(
    sqrt(mean((exp(pred_1_log) - test_sample$salario_hora)^2)), 
    sqrt(mean((exp(pred_7_log) - test_sample$salario_hora)^2))
  ),
  RMSE_LOOCV = c(rmse_m1_loocv_real, rmse_m7_loocv_real),
  RMSE_Leverage = c(rmse_m1_loocv_laverage_real, rmse_m7_loocv_laverage_real)
)

print(comparacion_rmse)
```

Comparación del error predictivo entre Validation Set Approach y LOOCV

Se compararon los errores predictivos de los modelos M1 y M7 utilizando dos métodos de validación: el Validation Set Approach (VSA) y el Leave-One-Out Cross-Validation (LOOCV). Los resultados muestran que el RMSE obtenido con LOOCV es menor que el obtenido con el VSA para ambos modelos, lo que sugiere que la evaluación con LOOCV es más estable y menos dependiente de cómo se divida la muestra. En particular, el RMSE de M7 sigue siendo menor que el de M1 en ambos métodos, lo que refuerza la conclusión de que M7 tiene mejor desempeño predictivo.

Relación con la estadística de influencia (Leverage)

Los valores de RMSE calculados con LOOCV utilizando leverage muestran que las diferencias con el LOOCV tradicional son mínimas (por ejemplo, para M7, pasa de 12723.80 a 12721.74). Esto sugiere que las observaciones con alto leverage no están afectando significativamente la estabilidad del modelo en términos de error predictivo. En términos prácticos, esto implica que aunque algunas observaciones pueden tener un alto leverage, su impacto sobre la predicción global del modelo no es significativo. Si hubiera diferencias marcadas entre LOOCV normal y LOOCV con leverage, eso indicaría que ciertos puntos influyentes distorsionan la estimación de los coeficientes y, por ende, del error predictivo.

Conclusión

El modelo M7 sigue siendo el mejor en términos de error predictivo, independientemente del método de validación utilizado. Además, la inclusión de leverage en los cálculos de LOOCV confirma que no hay observaciones individuales que estén afectando de manera desproporcionada la estabilidad del modelo. Esto da confianza en la robustez de los resultados obtenidos.

# Referencias

1.  Pinedo, W. C., del Aguila, W. C., & Alvarado, G. D. P. P. (2022). Un análisis de la evasión tributaria.Ciencia Latina Revista Científica Multidisciplinar,6(2), 3224-3241.

2.  Pedro A. Cabra-Acela, 2021. “Premiar a los buenos contribuyentes, ¿un mecanismo efectivo? ” Documentos CEDE19419, Universidad de los Andes, Facultad de Economía, CEDE.

3.  Leopoldo Fergusson & Carlos Molina & Juan Felipe Riaño, 2017. "Evado impuestos, ¿y qué? Una nueva base de datos y evidencia de Colombia",Documentos CEDE15444, Universidad de los Andes, Facultad de Economía, CEDE.

4.  Díaz, D. & González, J. (2024).Controles tributarios y la evasión fiscal en Colombia. [Proyecto aplicado]. Repositorio Institucional UNAD. <https://repository.unad.edu.co/handle/10596/64465>

5.  Bloom Monterroza, C. C. y Villalba Ayazo, D. S. (2024). Causas y consecuencias de la evasión tributaria [Tesis de pregrado, Universidad Cooperativa de Colombia]. Repositorio Institucional Universidad Cooperativa de Colombia <https://hdl.handle.net/20.500.12494/57925>

6.  El déficit fiscal de 2024 superaría la meta del Marco Fiscal de Mediano Plazo y el ajuste requerido para 2025 es mayor que el contemplado en el decreto de aplazamiento, (CARF, 2024)

7.  Rocha Combita, J. (2024) Elusion y evasion fiscal en Colombia. <https://bibliotecadigital.iue.edu.co/jspui/handle/20.500.12717/3192>

8.  Cuervo Alvarado, M. (2022). Análisis de los determinantes de las asignaciones salariales entre hombres y mujeres en la industria manufacturera en Bogotá 2016-201

9.  Sabogal, A. (2012). Brecha salarial entre hombres y mujeres y ciclo económico en Colombia.
